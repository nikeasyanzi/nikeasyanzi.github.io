<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Self hosting a local AI in a minute with Ollama and Open WebUI | Craig Yang's Dev Blog</title><meta name=keywords content="self-hosting,Ollama,OpenWebUI"><meta name=description content="Intro
With ollama and Open WebUI, self-hosting a chatgpt like service is possible. It&rsquo;s definitely a great news for people or corporations concerning about sharing their data with AI service providers.
In this article, I will show you how to setup a service in local environment.
Steps
First of all, there are 2 services we need to setup, and we will host the service on container.

Pull ollama container image

docker pull ollama/ollama:latest

Before we run the service, we need to download a model from ollama model. For experiment, we select llama3.2.


  "><meta name=author content="4rkal"><link rel=canonical href=https://nikeasyanzi.github.io/posts/self-hosting-chatgpt-in-a-minute/><link crossorigin=anonymous href=/assets/css/stylesheet.min.24117e94f7185554bf370e131546657a05d72834bf02c67c2a4215d5cf110a80.css integrity="sha256-JBF+lPcYVVS/Nw4TFUZlegXXKDS/AsZ8KkIV1c8RCoA=" rel="preload stylesheet" as=style><link rel=icon href=https://nikeasyanzi.github.io/4rkal.png><link rel=apple-touch-icon href=https://nikeasyanzi.github.io/apple-touch-icon.png><link rel=alternate hreflang=en href=https://nikeasyanzi.github.io/posts/self-hosting-chatgpt-in-a-minute/><meta name=twitter:card content="summary"><meta name=twitter:title content="Self hosting a local AI in a minute with Ollama and Open WebUI | Craig Yang's Dev Blog"><meta name=twitter:description content="Intro
With ollama and Open WebUI, self-hosting a chatgpt like service is possible. It&rsquo;s definitely a great news for people or corporations concerning about sharing their data with AI service providers.
In this article, I will show you how to setup a service in local environment.
Steps
First of all, there are 2 services we need to setup, and we will host the service on container.

Pull ollama container image

docker pull ollama/ollama:latest

Before we run the service, we need to download a model from ollama model. For experiment, we select llama3.2.


  "><meta property="og:title" content="Self hosting a local AI in a minute with Ollama and Open WebUI | Craig Yang's Dev Blog"><meta property="og:description" content="Intro
With ollama and Open WebUI, self-hosting a chatgpt like service is possible. It&rsquo;s definitely a great news for people or corporations concerning about sharing their data with AI service providers.
In this article, I will show you how to setup a service in local environment.
Steps
First of all, there are 2 services we need to setup, and we will host the service on container.

Pull ollama container image

docker pull ollama/ollama:latest

Before we run the service, we need to download a model from ollama model. For experiment, we select llama3.2.


  "><meta property="og:type" content="article"><meta property="og:url" content="https://nikeasyanzi.github.io/posts/self-hosting-chatgpt-in-a-minute/"><meta property="og:image" content="https://nikeasyanzi.github.io/4rkal.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-07-22T16:10:56+08:00"><meta property="article:modified_time" content="2025-07-22T16:10:56+08:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://nikeasyanzi.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Self hosting a local AI in a minute with Ollama and Open WebUI","item":"https://nikeasyanzi.github.io/posts/self-hosting-chatgpt-in-a-minute/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Self hosting a local AI in a minute with Ollama and Open WebUI | Craig Yang's Dev Blog","name":"Self hosting a local AI in a minute with Ollama and Open WebUI","description":"Intro With ollama and Open WebUI, self-hosting a chatgpt like service is possible. It\u0026rsquo;s definitely a great news for people or corporations concerning about sharing their data with AI service providers. In this article, I will show you how to setup a service in local environment.\nSteps First of all, there are 2 services we need to setup, and we will host the service on container.\nPull ollama container image docker pull ollama/ollama:latest Before we run the service, we need to download a model from ollama model. For experiment, we select llama3.2. ","keywords":["self-hosting","Ollama","OpenWebUI"],"wordCount":"271","inLanguage":"en","datePublished":"2025-07-22T16:10:56+08:00","dateModified":"2025-07-22T16:10:56+08:00","author":{"@type":"Person","name":"4rkal"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://nikeasyanzi.github.io/posts/self-hosting-chatgpt-in-a-minute/"},"publisher":{"@type":"Organization","name":"Craig Yang's Dev Blog","logo":{"@type":"ImageObject","url":"https://nikeasyanzi.github.io/4rkal.png"}}}</script><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript></head><body class="dark type-posts kind-page layout-" id=top><script data-no-instant>function switchTheme(e){switch(e){case"light":document.body.classList.remove("dark");break;case"dark":document.body.classList.add("dark");break;default:window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")}}function isDarkTheme(){return document.body.className.includes("dark")}function getPrefTheme(){return localStorage.getItem("pref-theme")}function setPrefTheme(e){switchTheme(e),localStorage.setItem("pref-theme",e)}const toggleThemeCallbacks={};toggleThemeCallbacks.main=e=>{setPrefTheme(e?"light":"dark")},window.addEventListener("toggle-theme",function(){const e=isDarkTheme();for(const t in toggleThemeCallbacks)toggleThemeCallbacks[t](e)});function toggleThemeListener(){window.dispatchEvent(new CustomEvent("toggle-theme"))}</script><script>(function(){const t="dark",e=getPrefTheme(),n=e||t;switchTheme(n)})()</script><header class=header><nav class=nav><div class=logo><a href=https://nikeasyanzi.github.io/ accesskey=h title="Craig Yang's Dev Blog (Alt + H)">Craig Yang's Dev Blog</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://nikeasyanzi.github.io/posts/ title=Posts class=active>Posts</a></li><li><a href=https://nikeasyanzi.github.io/about/ title=About>üìóAbout</a></li><li><a href=https://nikeasyanzi.github.io/search/ title="Search the site (Alt + /)" data-no-instant accesskey=/>üîç Search</a></li><li><a href=https://nikeasyanzi.github.io/archives/ title="üóÇÔ∏è archives">üóÇÔ∏è archives</a></li></ul></nav></header><main class="main post"><article class=post-single><header class=post-header><h1 class=post-title>Self hosting a local AI in a minute with Ollama and Open WebUI</h1><div class=post-meta><span class=meta-item><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select:text"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select:text"/><line x1="16" y1="2" x2="16" y2="6" style="user-select:text"/><line x1="8" y1="2" x2="8" y2="6" style="user-select:text"/><line x1="3" y1="10" x2="21" y2="10" style="user-select:text"/></svg>
<span>July 22, 2025</span></span><span class=meta-item>
<svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon" style="user-select:text"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z" style="user-select:text"/><line x1="7" y1="7" x2="7" y2="7" style="user-select:text"/></svg>
<span class=post-tags><a href=https://nikeasyanzi.github.io/tags/self-hosting/>Self-Hosting</a><a href=https://nikeasyanzi.github.io/tags/ollama/>Ollama</a><a href=https://nikeasyanzi.github.io/tags/openwebui/>OpenWebUI</a></span></span><span class=meta-item>
<svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text" style="user-select:text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z" style="user-select:text"/><polyline points="14 2 14 8 20 8" style="user-select:text"/><line x1="16" y1="13" x2="8" y2="13" style="user-select:text"/><line x1="16" y1="17" x2="8" y2="17" style="user-select:text"/><polyline points="10 9 9 9 8 9" style="user-select:text"/></svg>
<span>271 words</span></span><span class=meta-item>
<svg width="24" height="24" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>2 min</span></span></div></header><div class="toc side right"><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#intro aria-label=Intro>Intro</a></li><li><a href=#steps aria-label=Steps>Steps</a></li><li><a href=#docker-compose-with-service aria-label="Docker compose with service">Docker compose with service</a></li></ul></div></details></div><div class=post-content><h1 id=intro>Intro<a hidden class=anchor aria-hidden=true href=#intro>¬∂</a></h1><p>With <a href=https://ollama.com/>ollama</a> and <a href=https://github.com/open-webui/open-webui>Open WebUI</a>, self-hosting a chatgpt like service is possible. It&rsquo;s definitely a great news for people or corporations concerning about sharing their data with AI service providers.
In this article, I will show you how to setup a service in local environment.</p><h1 id=steps>Steps<a hidden class=anchor aria-hidden=true href=#steps>¬∂</a></h1><p>First of all, there are 2 services we need to setup, and we will host the service on container.</p><ol><li>Pull <a href=https://hub.docker.com/r/ollama/ollama>ollama container image</a></li></ol><pre tabindex=0><code class="language-bash=" data-lang="bash=">docker pull ollama/ollama:latest
</code></pre><ol start=2><li>Before we run the service, we need to download a model from <a href=https://ollama.com/models>ollama model</a>. For experiment, we select llama3.2.</li></ol><p><img loading=lazy src=https://i.imgur.com/iwluBge.png alt></p><p><img loading=lazy src=https://i.imgur.com/lnBbjDQ.png alt></p><pre tabindex=0><code class="language-bash=" data-lang="bash=">docker exec 5eeaf ollama pull llama3.2
</code></pre><p>Here, I select model llama3.2. It takes a while to download depends on the network and size of selected model.<br><img loading=lazy src=https://i.imgur.com/DfxrHZv.png alt></p><ol start=3><li>Run ollama service</li></ol><pre tabindex=0><code class="language-bash=" data-lang="bash=">docker run -d -v $(PWD):/root/.ollama -p 11434:11434 --name ollama ollama/ollama
</code></pre><ol start=4><li>Pull Open Web UI image</li></ol><pre tabindex=0><code class="language-bash=" data-lang="bash=">docker pull ghcr.io/open-webui/open-webui:latest
</code></pre><ol start=5><li>We create a folder named open-webui. Now, the directory lay out looks like the following.
We see the downloaded llama3.2 model and the new created open-webui folder for Open Web UI data placement..</li></ol><p><img loading=lazy src=https://i.imgur.com/OBRCjpR.png alt></p><ol start=7><li>Run Open Web UI image</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker run -d -p 3000:8080 --add-host<span class=o>=</span>host.docker.internal:host-gateway -v ./open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</span></span></code></pre></div><p>It would takes a while to get the container ready to work. Once, the status shows healthy, we can try to open http://localhost:3000
<img loading=lazy src=https://i.imgur.com/Z1FnT1m.png alt></p><ol start=8><li>For first time login, we will need to register a new account
<img loading=lazy src=https://i.imgur.com/iA3YErw.png alt></li><li>Once we log in with success, we can see the llama3.2 is selected and we can start to play with it.</li></ol><p><img loading=lazy src=https://i.imgur.com/WJLODOh.png alt></p><h1 id=docker-compose-with-service>Docker compose with service<a hidden class=anchor aria-hidden=true href=#docker-compose-with-service>¬∂</a></h1><p>I also write up a docker compose file, so we can host the file with one click. Check it out.
<a href=https://github.com/nikeasyanzi/my-toolbox/tree/main/ollama_openwebui>https://github.com/nikeasyanzi/my-toolbox/tree/main/ollama_openwebui</a></p></div><footer class=post-footer></footer><div class=comments-separator></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://nikeasyanzi.github.io/>Craig Yang's Dev Blog</a></span><span style=display:inline-block;margin-left:1em>
<a href=https://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA</a>
</span><span style=display:inline-block;margin-left:1em>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/reorx/hugo-PaperModX/ rel=noopener target=_blank>PaperModX</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){const t=""=="1";if(t)return;let e=document.getElementById("theme-toggle");e.removeEventListener("click",toggleThemeListener),e.addEventListener("click",toggleThemeListener)})()</script><script>(function(){let e=document.getElementById("menu");e&&(e.scrollLeft=localStorage.getItem("menu-scroll-position"),e.onscroll=function(){localStorage.setItem("menu-scroll-position",e.scrollLeft)});const t=""=="1",n=""=="1";if(window.matchMedia("(prefers-reduced-motion: reduce)").matches||t||n)return;document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})})()</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>if(window.scrollListeners)for(const e of scrollListeners)window.removeEventListener("scroll",e);window.scrollListeners=[]</script><script src=/js/medium-zoom.min.js data-no-instant></script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>(function(){const a="1"=="1";if(!a)return;if(!document.querySelector(".toc")){console.log("no toc found, ignore toc scroll");return}const r=window.scrollListeners,t=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id]"),n="active";let e=t[0];o(e).classList.add(n);const c=()=>{const s=[];for(const e of t)if(l(e)<5)s.push(e);else break;s.length>0?newActiveHeading=s[s.length-1]:newActiveHeading=t[0],e!=newActiveHeading&&(o(e).classList.remove(n),e=newActiveHeading,o(e).classList.add(n))};let s=null;const i=()=>{s!==null&&clearTimeout(s),s=setTimeout(c,50)};window.addEventListener("scroll",i,!1),r.push(i);function o(e){const t=encodeURI(e.getAttribute("id")).toLowerCase();return document.querySelector(`.toc ul li a[href="#${t}"]`)}function l(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect();return t.top}})()</script></body></html>