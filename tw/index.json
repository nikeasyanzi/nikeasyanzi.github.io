[{"content":"簡介 (Introduction) 在系統工程中，我們很容易將「技術上正確」視為終點線。\n但我從的經驗中學到，所謂的正確性仍然可能帶來糟糕的客戶體驗——尤其是當你的軟體介於混亂的現實（硬體、韌體、驅動程式）和那些只想要一個清晰訊號的人之間時：到底有沒有出問題？我需要馬上處理嗎？\n這是一個關於尷尬時刻的故事，它教會了我一個簡單的啟發法：有時候，軟體必須吸收硬體雜訊。\n問題：連鎖誤報 (The Problem: A Cascade of False Alarms) 我們運作一個 SSD 監控常駐程式 (daemon)，負責向客戶回報磨損指標。有一天，一位客戶升級通報了一個嚴重問題：他們的機群突然大規模觸發 SSD 磨損警報。\n時間點再糟糕不過了。他們的發布時程是以天計算，而不是以週計算。而且一場「SSD 健康危機」的警報風暴，足以讓所有決策停擺——即使系統實際上是正常的。\n我的直覺反應是標準的工程師反射動作：假設 bug 是我們造成的。\n於是我逐行檢查程式碼。令人沮喪的是，程式碼看起來無懈可擊。我們完全按照設計讀取作業系統訊號並如實回報。\n接著我們發現了令人不安的真相：訊號本身就是不穩定的 (flaky)。\n在我們的 daemon 底層，特定的 SSD 韌體會在較低層級產生偽陽性 (false positives)。而我們的軟體——身為「正確」的一方——正盡職地將這種不穩定性放大成面對客戶的警報。\n這造成了一個我不喜歡但無法避免的兩難：\n實作方式是 技術上正確的，但它卻因為產生雜訊而非可執行的資訊，導致我們 辜負了客戶。 這位客戶是第一位回報此事件的人，所以我們沒有既定的處理守則 (playbook)。 硬體供應商的退換貨流程 (RMA process) 需要數週時間。 客戶的發布就在幾天之後。 解決方案：啟發式過濾器 (The Solution: A Heuristic Filter) 我們需要一個快速、安全且誠實的方案。\n所以我實作了一個 啟發式過濾器 (heuristic filter)——也就是一種防抖動 (debouncing) 機制。\n用白話文說：我們不再是一看到單一的「磨損」訊號就發出警報，而是要求訊號必須在多次讀取中（或在一個短時間窗口內）持續存在。如果訊號是暫時性的，且在下一次檢查時消失，我們就將其視為雜訊。如果它持續存在，我們才視為真實情況。\n關鍵的權衡在於延遲 (latency)。我們的 daemon 每隔幾秒檢查一次訊號，所以「確認」訊號的持續性可能會將警報延遲幾秒鐘（有時是幾分鐘，取決於時間窗口）。\n對於 SSD 健康監控來說，這種輕微的延遲是划算的交易。磨損不是毫秒級的緊急事件；它是一種趨勢。在這種情境下，回報稍有延遲但值得信賴的警報，遠比用使用者無法採取行動的雜訊淹沒他們來得好。\n我與主管在溝通框架上達成了一致：\n這是一個務實的修補程式，目的是為了讓發布流程解鎖。我們不是在掩蓋問題——我們是在推動供應商提供永久修正的同時，先抑制雜訊。\n結果：解鎖與學習 (The Result: Unblocked and Learned) 修補程式順利部署。誤報立即停止。客戶如期發布了產品。\n話雖如此，更深層的問題（至今）仍是一個謎。我們尚未確認生產過程中導致這種不穩定行為的確切階段。我已請我們的磁碟團隊繼續追蹤，並推動根本原因的診斷。\n對我來說，更大的教訓不在於 SSD——而在於「正確性」在現實世界中的意義：\n「技術上正確」並不自帶「對客戶有用」的屬性。\n如果我們的工作是幫助客戶自信地運作系統，那麼我們的工作就不僅僅是傳遞訊號。而是要將充滿雜訊的現實，轉譯成穩定、可解釋且可採取行動的資訊。\n為了保護客戶體驗，你是否曾經必須在務實與完美之間做出選擇？我很樂意聽聽你的作法——以及你從中學到了什麼。\n","permalink":"https://nikeasyanzi.github.io/tw/posts/when-software-must-absorb-hardware-noise/","summary":"\u003ch2 id=\"簡介-introduction\"\u003e簡介 (Introduction)\u003c/h2\u003e\n\u003cp\u003e在系統工程中，我們很容易將「技術上正確」視為終點線。\u003c/p\u003e\n\u003cp\u003e但我從的經驗中學到，所謂的正確性仍然可能帶來糟糕的客戶體驗——尤其是當你的軟體介於混亂的現實（硬體、韌體、驅動程式）和那些只想要一個清晰訊號的人之間時：\u003cem\u003e到底有沒有出問題？我需要馬上處理嗎？\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e這是一個關於尷尬時刻的故事，它教會了我一個簡單的啟發法：有時候，軟體必須吸收硬體雜訊。\u003c/p\u003e\n\u003ch2 id=\"問題連鎖誤報-the-problem-a-cascade-of-false-alarms\"\u003e問題：連鎖誤報 (The Problem: A Cascade of False Alarms)\u003c/h2\u003e\n\u003cp\u003e我們運作一個 SSD 監控常駐程式 (daemon)，負責向客戶回報磨損指標。有一天，一位客戶升級通報了一個嚴重問題：他們的機群突然大規模觸發 SSD 磨損警報。\u003c/p\u003e\n\u003cp\u003e時間點再糟糕不過了。他們的發布時程是以天計算，而不是以週計算。而且一場「SSD 健康危機」的警報風暴，足以讓所有決策停擺——即使系統實際上是正常的。\u003c/p\u003e\n\u003cp\u003e我的直覺反應是標準的工程師反射動作：假設 bug 是我們造成的。\u003c/p\u003e\n\u003cp\u003e於是我逐行檢查程式碼。令人沮喪的是，程式碼看起來無懈可擊。我們完全按照設計讀取作業系統訊號並如實回報。\u003c/p\u003e\n\u003cp\u003e接著我們發現了令人不安的真相：\u003cstrong\u003e訊號本身就是不穩定的 (flaky)\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e在我們的 daemon 底層，特定的 SSD 韌體會在較低層級產生偽陽性 (false positives)。而我們的軟體——身為「正確」的一方——正盡職地將這種不穩定性放大成面對客戶的警報。\u003c/p\u003e\n\u003cp\u003e這造成了一個我不喜歡但無法避免的兩難：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e實作方式是 \u003cstrong\u003e技術上正確的\u003c/strong\u003e，但它卻因為產生雜訊而非可執行的資訊，導致我們 \u003cstrong\u003e辜負了客戶\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e這位客戶是第一位回報此事件的人，所以我們沒有既定的處理守則 (playbook)。\u003c/li\u003e\n\u003cli\u003e硬體供應商的退換貨流程 (RMA process) 需要數週時間。\u003c/li\u003e\n\u003cli\u003e客戶的發布就在幾天之後。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"解決方案啟發式過濾器-the-solution-a-heuristic-filter\"\u003e解決方案：啟發式過濾器 (The Solution: A Heuristic Filter)\u003c/h2\u003e\n\u003cp\u003e我們需要一個快速、安全且誠實的方案。\u003c/p\u003e\n\u003cp\u003e所以我實作了一個 \u003cstrong\u003e啟發式過濾器 (heuristic filter)\u003c/strong\u003e——也就是一種防抖動 (debouncing) 機制。\u003c/p\u003e\n\u003cp\u003e用白話文說：我們不再是一看到單一的「磨損」訊號就發出警報，而是要求訊號必須在多次讀取中（或在一個短時間窗口內）持續存在。如果訊號是暫時性的，且在下一次檢查時消失，我們就將其視為雜訊。如果它持續存在，我們才視為真實情況。\u003c/p\u003e\n\u003cp\u003e關鍵的權衡在於延遲 (latency)。我們的 daemon 每隔幾秒檢查一次訊號，所以「確認」訊號的持續性可能會將警報延遲幾秒鐘（有時是幾分鐘，取決於時間窗口）。\u003c/p\u003e\n\u003cp\u003e對於 SSD 健康監控來說，這種輕微的延遲是划算的交易。磨損不是毫秒級的緊急事件；它是一種趨勢。在這種情境下，回報稍有延遲但值得信賴的警報，遠比用使用者無法採取行動的雜訊淹沒他們來得好。\u003c/p\u003e\n\u003cp\u003e我與主管在溝通框架上達成了一致：\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e這是一個務實的修補程式，目的是為了讓發布流程解鎖。我們不是在掩蓋問題——我們是在推動供應商提供永久修正的同時，先抑制雜訊。\u003c/em\u003e\u003c/p\u003e\n\u003ch2 id=\"結果解鎖與學習-the-result-unblocked-and-learned\"\u003e結果：解鎖與學習 (The Result: Unblocked and Learned)\u003c/h2\u003e\n\u003cp\u003e修補程式順利部署。誤報立即停止。客戶如期發布了產品。\u003c/p\u003e","title":"誤報啟發法：當軟體必須吸收硬體雜訊 (The False Alarm Heuristic: When Software Must Absorb Hardware Noise)"},{"content":"可觀測性 (Observability) 來源\n可觀測性是一種實踐方法，透過對系統進行埋點來收集數據，讓你能夠從外部了解系統的內部狀態。\n在現代複雜的環境中，如微服務架構，我們需要分層的可觀測性來幫助我們了解從業務層到底層基礎設施的狀態。可觀測性讓你能夠透過對系統行為提出任意問題，來探索和除錯那些你從未見過的問題（「未知的未知」）。\n上圖金字塔清楚描繪了一個常見的業務場景：從發現服務停止運作，到 IT 團隊需要深入調查事件的過程。\n為了達成這個目標，應用程式必須進行埋點以發送遙測數據 (Telemetry)——關於其效能和行為的數據。這些數據通常被分為三個基礎支柱。\n可觀測性的三大支柱 來源\n雖然指標、日誌和追蹤常被稱為「三大支柱」，但它們真正的威力在於相互關聯，讓你能夠在它們之間無縫切換來診斷問題。\n1. 指標 (Metrics)：「發生了什麼」 指標是在一段時間內收集的聚合數值數據。它們非常適合用來快速了解系統的整體健康狀況以及設定警報。例如：CPU 使用率、API 回應時間\n它們能回答的問題：「CPU 使用率是多少？」、「我的 API 錯誤率是多少？」、「我們每秒處理多少請求？」\n關鍵概念：\n維度 (Dimensionality)： 當指標具有維度（也稱為標籤或標記）時會更加強大，維度是提供上下文的鍵值對。例如，不只是 http_requests_total，你可以有 http_requests_total{method=\u0026quot;POST\u0026quot;, status=\u0026quot;500\u0026quot;}。\n基數 (Cardinality)： 這是指維度的唯一組合數量。高基數（例如使用唯一的 userID 作為維度）對於監控系統的儲存和查詢效率來說是個挑戰。隨著時間序列數量的增長，查詢變得更加消耗計算資源。此外，任何重大事件，例如涉及不可變基礎設施的程式碼發布，都會導致大量同時寫入資料庫的操作。\n典型工具： Prometheus 是收集和儲存時間序列指標數據的領先開源工具。\n2. 日誌 (Logs)：「為什麼發生」 日誌是在特定時間發生的離散事件的帶時間戳、不可變的記錄。日誌提供了關於應用程式或系統內部發生什麼的最詳細、最細緻的上下文。例如：系統錯誤訊息或異常事件\n它們能回答的問題：「為什麼這個特定請求失敗了？」、「確切的錯誤訊息是什麼？」、「導致這次崩潰的事件順序是什麼？」\n典型工具： Grafana Loki 是一個日誌聚合系統，設計目標是成本效益高且易於操作，特別是與 Prometheus 等其他工具整合時。\n3. 追蹤 (Traces)：「在哪裡發生」 追蹤代表單一請求在分散式系統中穿越所有不同服務的端到端旅程。Span 追蹤請求發出的特定操作，描繪出在該操作執行期間發生了什麼。\n例如：在 iThome 使用 Facebook 的 SSO（單一登入），一個單純的登入「請求」，可能就橫跨了 iThome 的後端服務、Facebook 的 SSO 後端、iThome 的 Redis，這些衍生出來的請求，與最初的登入請求結合起來呈現的歷程就稱為 Trace\n它們能回答的問題：「這個使用者請求的延遲在哪裡？」、「哪個下游服務造成了瓶頸？」、「這個 API 呼叫通過我們微服務的完整路徑是什麼？」\n典型工具： Grafana Tempo 是一個分散式追蹤後端，可以從各種來源儲存和檢索追蹤。\n追蹤中的每個工作單位稱為 span。\n單一追蹤中有大量 span： 這表示一個請求穿越了許多不同的服務或執行了大量操作。雖然這本身不一定是問題，但具有大量 span 的追蹤可能意味著高度複雜的交互，或者如果一個簡單的請求涉及太多微服務，可能是設計效率不佳。這可能使追蹤的視覺化呈現更加密集，但追蹤的主要目的就是繪製出這些複雜的旅程。\n持續時間很長的 span（即在該 span 中花費了「大量」時間）： 這是追蹤提供的直接且關鍵的洞察。如果某個特定 span 持續時間很長，這意味著該 span 代表的特定操作或服務需要很長時間才能完成。這正是追蹤設計用來幫助識別的：\n「這個使用者請求的延遲在哪裡？」 「哪個下游服務造成了瓶頸？」 因此，持續時間「高」的 span 會精確定位系統中的效能瓶頸，讓你能夠進一步調查該特定操作或服務，可能透過跳轉到該服務在該確切時間的日誌來找到根本原因。\n透過視覺化整合一切 最終目標是將這些支柱結合使用。典型的工作流程可能是：\n從指標觸發警報（例如，延遲過高）。 查看慢請求的追蹤，看看哪個特定服務是瓶頸。 從該追蹤跳轉到該服務在該確切時間的日誌，找到根本原因的錯誤訊息。 Grafana 是建立儀表板的事實標準工具，用於在單一介面中視覺化和關聯來自所有三個支柱的數據。\n使用 OpenTelemetry 實現可觀測性 手動埋點程式碼以產生所有這些數據可能很複雜。OpenTelemetry 是一個廠商中立的開源可觀測性框架。它提供了一套標準化的 API、函式庫和代理程式，用於從應用程式收集和匯出遙測數據（指標、日誌和追蹤），使你不會被鎖定在單一廠商的生態系統中。\n應用可觀測性：衡量服務可靠性 SLO vs SLA vs SLI 的區別\n一旦你擁有豐富的遙測數據，你就可以超越單純的錯誤修復，開始衡量對使用者和業務真正重要的事情。這是透過 SLI、SLO 和 SLA 框架來完成的。\n1. 服務級別指標 (SLIs) SLI 是服務效能的直接、可量化的衡量標準。它是你從可觀測性工具獲得的原始數據。\n範例： 成功 HTTP 請求的百分比，或 95% 請求的延遲。 2. 服務級別目標 (SLOs) SLO 是你為某個 SLI 在一段時間內設定的內部目標。這是你的工程團隊努力達成的目標。\n範例： 在 30 天內，99.9% 的 API 請求將會成功。 3. 服務級別協議 (SLAs) SLA 是對客戶的正式承諾，通常是合約性的，定義了如果未達到 SLO 的後果（例如，經濟處罰或服務抵免）。SLA 通常比內部 SLO 寬鬆，以提供緩衝。\n範例： 承諾每月 99.5% 的正常運行時間，如果違反則提供 10% 的帳單抵免。 這個框架將可觀測性平台的技術數據直接與業務和客戶滿意度目標連結起來。\n可觀測性 可觀測性讓你能夠從外部了解系統，透過對該系統提問，而無需知道其內部運作方式。\n參考資料 Observability primer\nObservability at Twitter: technical overview, part I\nObservability at Twitter: technical overview, part II [Observability 的過去與現在] https://ithelp.ithome.com.tw/m/articles/10319113\nWhy Your Observability Strategy Needs High Cardinality Data\nUnderstanding High Cardinality in Observability\n","permalink":"https://nikeasyanzi.github.io/tw/posts/observability/","summary":"\u003ch1 id=\"可觀測性-observability\"\u003e可觀測性 (Observability)\u003c/h1\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://i.imgur.com/FEPLgvU.png\"\u003e\n\u003ca href=\"https://developer.ibm.com/articles/observability-insights-and-automation/\"\u003e來源\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e可觀測性\u003c/strong\u003e是一種實踐方法，透過對系統進行埋點來收集數據，讓你能夠從外部了解系統的內部狀態。\u003c/p\u003e\n\u003cp\u003e在現代複雜的環境中，如微服務架構，我們需要分層的可觀測性來幫助我們了解從業務層到底層基礎設施的狀態。可觀測性讓你能夠透過對系統行為提出任意問題，來探索和除錯那些你從未見過的問題（「未知的未知」）。\u003c/p\u003e\n\u003cp\u003e上圖金字塔清楚描繪了一個常見的業務場景：從發現服務停止運作，到 IT 團隊需要深入調查事件的過程。\u003c/p\u003e\n\u003cp\u003e為了達成這個目標，應用程式必須進行埋點以發送\u003cstrong\u003e遙測數據 (Telemetry)\u003c/strong\u003e——關於其效能和行為的數據。這些數據通常被分為三個基礎支柱。\u003c/p\u003e\n\u003ch2 id=\"可觀測性的三大支柱\"\u003e可觀測性的三大支柱\u003c/h2\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://i.imgur.com/OU4NjDB.png\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://developer.ibm.com/articles/observability-insights-and-automation/\"\u003e來源\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e雖然指標、日誌和追蹤常被稱為「三大支柱」，但它們真正的威力在於相互關聯，讓你能夠在它們之間無縫切換來診斷問題。\u003c/p\u003e\n\u003ch3 id=\"1-指標-metrics發生了什麼\"\u003e1. 指標 (Metrics)：「發生了什麼」\u003c/h3\u003e\n\u003cp\u003e指標是在一段時間內收集的聚合數值數據。它們非常適合用來快速了解系統的整體健康狀況以及設定警報。例如：CPU 使用率、API 回應時間\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e它們能回答的問題：\u003c/strong\u003e「CPU 使用率是多少？」、「我的 API 錯誤率是多少？」、「我們每秒處理多少請求？」\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e關鍵概念：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e維度 (Dimensionality)：\u003c/strong\u003e 當指標具有維度（也稱為標籤或標記）時會更加強大，維度是提供上下文的鍵值對。例如，不只是 \u003ccode\u003ehttp_requests_total\u003c/code\u003e，你可以有 \u003ccode\u003ehttp_requests_total{method=\u0026quot;POST\u0026quot;, status=\u0026quot;500\u0026quot;}\u003c/code\u003e。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e基數 (Cardinality)：\u003c/strong\u003e 這是指維度的唯一組合數量。\u003cstrong\u003e高基數\u003c/strong\u003e（例如使用唯一的 \u003ccode\u003euserID\u003c/code\u003e 作為維度）對於監控系統的儲存和查詢效率來說是個挑戰。隨著時間序列數量的增長，查詢變得更加消耗計算資源。此外，任何重大事件，例如涉及不可變基礎設施的程式碼發布，都會導致大量同時寫入資料庫的操作。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e典型工具：\u003c/strong\u003e \u003cstrong\u003ePrometheus\u003c/strong\u003e 是收集和儲存時間序列指標數據的領先開源工具。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"2-日誌-logs為什麼發生\"\u003e2. 日誌 (Logs)：「為什麼發生」\u003c/h3\u003e\n\u003cp\u003e日誌是在特定時間發生的離散事件的帶時間戳、不可變的記錄。日誌提供了關於應用程式或系統內部發生什麼的最詳細、最細緻的上下文。例如：系統錯誤訊息或異常事件\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e它們能回答的問題：\u003c/strong\u003e「為什麼這個特定請求失敗了？」、「確切的錯誤訊息是什麼？」、「導致這次崩潰的事件順序是什麼？」\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e典型工具：\u003c/strong\u003e \u003cstrong\u003eGrafana Loki\u003c/strong\u003e 是一個日誌聚合系統，設計目標是成本效益高且易於操作，特別是與 Prometheus 等其他工具整合時。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"3-追蹤-traces在哪裡發生\"\u003e3. 追蹤 (Traces)：「在哪裡發生」\u003c/h3\u003e\n\u003cp\u003e追蹤代表單一請求在分散式系統中穿越所有不同服務的端到端旅程。Span 追蹤請求發出的特定操作，描繪出在該操作執行期間發生了什麼。\u003c/p\u003e\n\u003cp\u003e例如：在 iThome 使用 Facebook 的 SSO（單一登入），一個單純的登入「請求」，可能就橫跨了 iThome 的後端服務、Facebook 的 SSO 後端、iThome 的 Redis，這些衍生出來的請求，與最初的登入請求結合起來呈現的歷程就稱為 Trace\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e它們能回答的問題：\u003c/strong\u003e「這個使用者請求的延遲在哪裡？」、「哪個下游服務造成了瓶頸？」、「這個 API 呼叫通過我們微服務的完整路徑是什麼？」\u003c/p\u003e","title":"可觀測性 Observability"},{"content":"這是中文內容。\n","permalink":"https://nikeasyanzi.github.io/tw/chinese-post/","summary":"\u003cp\u003e這是中文內容。\u003c/p\u003e","title":"我的中文文章"},{"content":"簡介 (Introduction) 在本文中，我們將展示如何使用 Alloy 和 Loki 有效地收集日誌。 透過這種方式，來自應用程式和基礎設施的遙測訊號會被匯出到統一的位置，以便未來進行遙測分析。\n在實驗練習中，我們將嘗試設置 Nginx 服務，搭配 Loki、Alloy，並在 Grafana 上觀察系統日誌。\n配置深入探討 (Configuration deep dive) Grafana Alloy 配置 我們使用配置檔案 config.alloy，其中包含要收集的日誌以及要轉發到哪裡。\nLoki 配置 Grafana Loki 需要一個配置檔案來定義其運行方式。在 loki-fundamentals 目錄中，你會找到一個名為 loki-config.yaml 的檔案。\nGrafana Loki 資料來源 Grafana 使用此配置來連接 Loki 並查詢日誌。Grafana 有多種方式定義資料來源：\nDirect（直接）：在 Grafana UI 中定義資料來源。 Provisioning（佈建）：在配置檔案中定義資料來源，讓 Grafana 自動建立資料來源。 API：使用 Grafana API 建立資料來源。 在接下來的實驗部分，我們使用佈建方法。我們已在 docker-compose.yml 檔案的這部分定義了資料來源：\n實驗練習 (Lab exercise) 完整的配置和 docker-compose 檔案可以在這裡找到。 在這個儲存庫中： config.alloy 是 Alloy 的配置檔案。 loki-config.yam 是 Loki 的配置檔案。 grafana-dashboard.json grafana-datasources.yml 定義了 Grafana 的資料來源 grafana-default.yaml grafana-data 是 Grafana 資料庫的資料夾\n啟動服務 (Starting the service) docker-compose -f ./docker-compose.yml up -d 接下來，我們檢查服務狀態。\nnginx http://10.122.168.81:8082/stub_status loki http://localhost:3100/metrics alloy http://localhost:12345/ 檢查 Alloy 狀態時，我們看到 Loki 元件已啟動並正在運行。 我們也可以瀏覽 Alloy UI，網址為 http://localhost:12345/graph，以視覺化方式查看配置檔案 config.alloy。該配置檔案定義了要收集的日誌以及要轉發到哪裡。\ndiscovery.docker：此元件透過 Docker socket 查詢 Docker 環境的中繼資料，並發現新容器，同時提供容器的中繼資料。\ndiscovery.relabel：此元件將中繼資料（__meta_docker_container_name）標籤轉換為 Loki 標籤（container）。\nloki.source.docker：此元件從發現的容器中收集日誌，並將其轉發到下一個元件。它從 discovery.docker 元件請求中繼資料，並套用來自 discovery.relabel 元件的重新標記規則。\nloki.process：此元件提供日誌轉換和擷取的階段。在這種情況下，它會為所有日誌新增一個靜態標籤 env=production。\nloki.write：此元件將日誌寫入 Loki。它將日誌轉發到 Loki 端點 http://loki:3100/loki/api/v1/push。\n接下來，我們配置 Grafana 來視覺化 Loki 收集的資料。 點擊 Save\u0026amp;test 檢查連線狀態。 檢查服務日誌 (Check logs of our services) 服務啟動並運行後，我們可以瀏覽 http://localhost:3000/drilldown。 選擇 Logs。你應該會看到 Grafana Logs Drilldown 頁面。\n我們可以看到 Alloy 能夠追蹤 Nginx 日誌，其他容器的日誌也被收集了。 查詢日誌 (Query logs) 要手動查詢 Loki 以詢問更進階的日誌問題，我們使用 Grafana Explore。 開啟瀏覽器並瀏覽 http://localhost:3000 以開啟 Grafana。 從 Grafana 主選單中，點擊 Explore 圖示 (1) 以開啟 Explore 分頁。 點擊 Code 以在程式碼模式下工作，並輸入 {container=\u0026ldquo;nginx\u0026rdquo;} 另外，我們每 30 秒持續重啟 Nginx 服務。\n#!/bin/bash for i in {1..6}; do echo \u0026#34;This is loop number $i\u0026#34; docker restart nginx sleep 30 done How to add my application log to Grafana 如何自訂application log 呢？ 從官網給的greenhouse 範例, 在in main_app.py, 我們看到\nlogging.basicConfig( format=\u0026#39;ts=%(asctime)s,%(msecs)03d level=%(levelname)s line=%(lineno)d msg=\u0026#34;%(message)s\u0026#34;\u0026#39;, datefmt=\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39; ) log = logging.getLogger(\u0026#39;werkzeug\u0026#39;) log.setLevel(logging.INFO) 所以其實寫到 system log 即可\n結論 (Conclusion) 本文展示了如何使用以下工具建立日誌收集系統： Grafana Alloy、Loki 和 Grafana。\n如何使用 Grafana Alloy 收集日誌並發送到 Loki 如何在 Grafana 中配置收集到的日誌。 總而言之，此解決方案提供了一種方法，可以將原本在本地產生的日誌重新導向到遠端 Grafana 伺服器。這提供了統一的介面。\n參考資料 (Reference) https://medium.com/@venkat65534/full-stack-observability-with-grafana-prometheus-loki-tempo-and-opentelemetry-90839113d17d\nhttps://github.com/grafana/loki-fundamentals\nhttps://grafana.com/docs/loki/latest/get-started/quick-start/tutorial/\nhttps://github.com/grafana/docker-monitor-workshop\nhttps://ithelp.ithome.com.tw/articles/10335935\nhttps://medium.com/@fawenyo/python-%E7%9B%A3%E6%8E%A7-prometheus-loki-grafana-25ead4bbb681\nhttps://medium.com/@derekjan1240/grafana-loki-prometheus-with-docker-compose-75d431bd07e2\n","permalink":"https://nikeasyanzi.github.io/tw/posts/system-log-collection-with-grafana-loki-and-alloy/","summary":"\u003ch1 id=\"簡介-introduction\"\u003e簡介 (Introduction)\u003c/h1\u003e\n\u003cp\u003e在本文中，我們將展示如何使用 \u003ca href=\"https://github.com/grafana/alloy\"\u003eAlloy\u003c/a\u003e 和 \u003ca href=\"https://github.com/grafana/loki\"\u003eLoki\u003c/a\u003e 有效地收集日誌。\n透過這種方式，來自應用程式和基礎設施的遙測訊號會被匯出到統一的位置，以便未來進行遙測分析。\u003c/p\u003e\n\u003cp\u003e在實驗練習中，我們將嘗試設置 Nginx 服務，搭配 Loki、Alloy，並在 Grafana 上觀察系統日誌。\u003c/p\u003e\n\u003ch1 id=\"配置深入探討-configuration-deep-dive\"\u003e配置深入探討 (Configuration deep dive)\u003c/h1\u003e\n\u003ch2 id=\"grafana-alloy-配置\"\u003eGrafana Alloy 配置\u003c/h2\u003e\n\u003cp\u003e我們使用配置檔案 \u003ccode\u003econfig.alloy\u003c/code\u003e，其中包含要收集的日誌以及要轉發到哪裡。\u003c/p\u003e\n\u003ch2 id=\"loki-配置\"\u003eLoki 配置\u003c/h2\u003e\n\u003cp\u003eGrafana Loki 需要一個配置檔案來定義其運行方式。在 loki-fundamentals 目錄中，你會找到一個名為 \u003cem\u003eloki-config.yaml\u003c/em\u003e 的檔案。\u003c/p\u003e\n\u003ch2 id=\"grafana-loki-資料來源\"\u003eGrafana Loki 資料來源\u003c/h2\u003e\n\u003cp\u003eGrafana 使用此配置來連接 Loki 並查詢日誌。Grafana 有多種方式定義資料來源：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDirect（直接）：在 Grafana UI 中定義資料來源。\u003c/li\u003e\n\u003cli\u003eProvisioning（佈建）：在配置檔案中定義資料來源，讓 Grafana 自動建立資料來源。\u003c/li\u003e\n\u003cli\u003eAPI：使用 Grafana API 建立資料來源。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e在接下來的實驗部分，我們使用佈建方法。我們已在 docker-compose.yml 檔案的這部分定義了資料來源：\u003c/p\u003e\n\u003ch1 id=\"實驗練習-lab-exercise\"\u003e實驗練習 (Lab exercise)\u003c/h1\u003e\n\u003cp\u003e完整的配置和 docker-compose 檔案可以在\u003ca href=\"https://github.com/nikeasyanzi/loki-alloy-Grafana\"\u003e這裡\u003c/a\u003e找到。\n在這個儲存庫中：\n\u003cem\u003econfig.alloy\u003c/em\u003e 是 Alloy 的配置檔案。\n\u003cem\u003eloki-config.yam\u003c/em\u003e 是 Loki 的配置檔案。\ngrafana-dashboard.json\ngrafana-datasources.yml 定義了 Grafana 的資料來源\ngrafana-default.yaml\ngrafana-data 是 Grafana 資料庫的資料夾\u003c/p\u003e","title":"使用 Grafana Loki 和 Alloy 收集系統日誌"},{"content":"簡介 (Introduction) 現今在微服務架構中，工程師會架設多個容器來提供服務，容器監控成為熱門議題。在本文中，我們使用 cAdvisor 來監控主機上所有運行的容器，並使用 Grafana 視覺化資料。\n設定 (Setup) 本實驗的腳本 https://github.com/nikeasyanzi/Prometheus-Grafana-Cadvisor-Docker\n以下是 docker compose 檔案中 cadvisor 的配置。\ncadvisor: container_name: cadvisor image: gcr.io/cadvisor/cadvisor:latest ports: - \u0026#34;8080:8080\u0026#34; privileged: true volumes: - \u0026#34;/:/rootfs:ro\u0026#34; - \u0026#34;/var/run:/var/run:rw\u0026#34; - \u0026#34;/var/lib/docker/:/var/lib/docker\u0026#34; - \u0026#34;/sys:/sys:ro\u0026#34; - \u0026#34;/dev/disk/:/dev/disk\u0026#34; devices: - \u0026#34;/dev/kmsg\u0026#34; # for kernel message 所有容器啟動並運行後， 我們透過連結 http://localhost:8080/containers/ 檢查 cAdvisor。 我們可以看到所有運行中的容器清單\n另外，向下捲動頁面，我們可以看到每個容器運行時的 CPU 和記憶體使用情況。 然後我們前往 Grafana，http://localhost:3000 我們新增一個儀表板來視覺化容器的資料。\n用於 cadvisor：https://grafana.com/grafana/dashboards/13946 為了實驗目的，我們使用 k6 壓力測試來產生流量，並觀察流量是否反映在我們的系統上。 切換到儀表板並在底部，我們可以看到 RX/TX 流量進來。 結論 (Conclusion) 我們成功建立了容器監控系統。包括 1. 設置 cAdvisor 來監控容器指標 2. 整合 cAdvisor 與 Grafana 進行視覺化\n此外，我們使用 k6 產生負載來驗證系統能力。\n參考資料 (Reference) https://medium.com/@jsantoine24/monitoring-docker-containers-with-cadvisor-ed21a9cfae95 https://blog.darkthread.net/blog/cadvisor-prometheus-grafana/\nhttps://medium.com/@sohammohite/docker-container-monitoring-with-cadvisor-prometheus-and-grafana-using-docker-compose-b47ec78efbc\nhttps://blog.devops.dev/monitoring-with-cadvisor-prometheus-and-grafana-on-docker-8fc5c4a2eae7\nhttps://medium.com/@varunjain2108/monitoring-docker-containers-with-cadvisor-prometheus-and-grafana-d101b4dbbc84\n","permalink":"https://nikeasyanzi.github.io/tw/posts/container-monitoring-with-cadvisor/","summary":"\u003ch1 id=\"簡介-introduction\"\u003e簡介 (Introduction)\u003c/h1\u003e\n\u003cp\u003e現今在微服務架構中，工程師會架設多個容器來提供服務，容器監控成為熱門議題。在本文中，我們使用 \u003ca href=\"https://github.com/google/cadvisor\"\u003ecAdvisor\u003c/a\u003e 來監控主機上所有運行的容器，並使用 Grafana 視覺化資料。\u003c/p\u003e\n\u003ch1 id=\"設定-setup\"\u003e設定 (Setup)\u003c/h1\u003e\n\u003cp\u003e本實驗的腳本\n\u003ca href=\"https://github.com/nikeasyanzi/Prometheus-Grafana-Cadvisor-Docker\"\u003ehttps://github.com/nikeasyanzi/Prometheus-Grafana-Cadvisor-Docker\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e以下是 docker compose 檔案中 cadvisor 的配置。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003ecadvisor\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003econtainer_name\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003ecadvisor\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003eimage\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003egcr.io/cadvisor/cadvisor:latest\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003eports\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    - \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;8080:8080\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003eprivileged\u003c/span\u003e: \u003cspan style=\"color:#66d9ef\"\u003etrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003evolumes\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    - \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;/:/rootfs:ro\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    - \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;/var/run:/var/run:rw\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    - \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;/var/lib/docker/:/var/lib/docker\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    - \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;/sys:/sys:ro\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    - \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;/dev/disk/:/dev/disk\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003edevices\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    - \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;/dev/kmsg\u0026#34;\u003c/span\u003e \u003cspan style=\"color:#75715e\"\u003e#  for kernel message\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e所有容器啟動並運行後，\n\u003cimg loading=\"lazy\" src=\"https://i.imgur.com/d072x3l.png\"\u003e\u003c/p\u003e\n\u003cp\u003e我們透過連結 \u003ca href=\"http://localhost:8080/containers/\"\u003ehttp://localhost:8080/containers/\u003c/a\u003e 檢查 cAdvisor。\n我們可以看到所有運行中的容器清單\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://i.imgur.com/tLmdWTM.png\"\u003e\u003c/p\u003e\n\u003cp\u003e另外，向下捲動頁面，我們可以看到每個容器運行時的 CPU 和記憶體使用情況。\n\u003cimg loading=\"lazy\" src=\"https://i.imgur.com/nTzL1Do.png\"\u003e\u003c/p\u003e\n\u003cp\u003e然後我們前往 Grafana，\u003ca href=\"http://localhost:3000\"\u003ehttp://localhost:3000\u003c/a\u003e\n我們新增一個儀表板來視覺化容器的資料。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e用於 cadvisor：\u003ca href=\"https://grafana.com/grafana/dashboards/13946\"\u003ehttps://grafana.com/grafana/dashboards/13946\u003c/a\u003e\n\u003cimg loading=\"lazy\" src=\"https://i.imgur.com/hoyOB6h.png\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e為了實驗目的，我們使用 k6 壓力測試來產生流量，並觀察流量是否反映在我們的系統上。\n\u003cimg loading=\"lazy\" src=\"https://i.imgur.com/IBNiAJE.png\"\u003e\u003c/p\u003e\n\u003cp\u003e切換到儀表板並在底部，我們可以看到 RX/TX 流量進來。\n\u003cimg loading=\"lazy\" src=\"https://i.imgur.com/4WkcDFI.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"結論-conclusion\"\u003e結論 (Conclusion)\u003c/h1\u003e\n\u003cp\u003e我們成功建立了容器監控系統。包括 1. 設置 cAdvisor 來監控容器指標 2. 整合 cAdvisor 與 Grafana 進行視覺化\u003c/p\u003e","title":"使用 cAdvisor 進行容器監控"},{"content":"簡介 (Introduction) 在本文中，我們將展示\n如何使用 Prometheus 來收集和監控我們的主機與 Nginx 服務。 在 Grafana 中視覺化呈現收集到的指標 元件 (Components) Prometheus 收集並儲存時間序列資料形式的指標，亦即指標資訊會與記錄時的時間戳記一起儲存，以及稱為標籤的選用鍵值對。 Prometheus node exporter 公開各種與硬體和核心相關的指標。 Grafana 一種圖形化處理軟體，可支援不同型式的來源資料數據，並以豐富的圖形來呈現相關數據 配置 (Configuration) 更新 docker-compose services: nginx: image: nginx:latest container_name: nginx volumes: - ./nginx/:/etc/nginx/conf.d ports: - 8082:8080 nginx-prometheus-exporter: image: nginx/nginx-prometheus-exporter:1.4 container_name: nginx-prometheus-exporter command: -nginx.scrape-uri http://nginx:8080/stub_status ports: - 9113:9113 depends_on: - nginx # System monitoring node-exporter: container_name: node-exporter image: prom/node-exporter ports: - 9100:9100 prometheus: image: prom/prometheus:latest container_name: prometheus volumes: - ./prometheus.yaml:/etc/prometheus/prometheus.yaml - ./prometheus_data:/prometheus command: - \u0026#34;--config.file=/etc/prometheus/prometheus.yaml\u0026#34; ports: - \u0026#34;9090:9090\u0026#34; depends_on: - node-exporter - nginx-prometheus-exporter #handles rendering panels \u0026amp; dashboards to PNGs renderer: image: grafana/grafana-image-renderer:3.4.2 environment: BROWSER_TZ: Asia/Taipei ports: - \u0026#34;8081:8081\u0026#34; grafana: image: grafana/grafana:latest container_name: grafana volumes: - ./grafana_data:/var/lib/grafana environment: GF_SECURITY_ADMIN_PASSWORD: pass GF_RENDERING_SERVER_URL: http://renderer:8081/render GF_RENDERING_CALLBACK_URL: http://grafana:3000/ GF_LOG_FILTERS: rendering:debug depends_on: - prometheus ports: - \u0026#34;3000:3000\u0026#34; 更新 prometheus.yaml 配置 Prometheus 抓取間隔\nglobal: scrape_interval: 5s # Server 抓取頻率 external_labels: monitor: \u0026#34;my-monitor\u0026#34; scrape_configs: - job_name: \u0026#34;prometheus\u0026#34; static_configs: - targets: [\u0026#34;localhost:9090\u0026#34;] - job_name: \u0026#34;node_exporter\u0026#34; static_configs: - targets: [\u0026#34;node-exporter:9100\u0026#34;] - job_name: \u0026#34;nginx_exporter\u0026#34; static_configs: - targets: [\u0026#34;nginx-prometheus-exporter:9113\u0026#34;] 啟動服務 (Start services) 現在，我們使用 docker-compose 來啟動服務。\n執行 docker-compose.yaml docker-compose -f ./docker-compose.yaml up -d 檢查服務狀態 服務檢查與疑難排解 (Service check and troubleshooting) 接下來，我們檢查服務狀態並確保指標已在瀏覽器上匯出。\nNginx 服務狀態 http://localhost:8082/\n檢查 Nginx 匯出的指標 http://localhost:8082/stub_status Nginx 狀態資訊 * Active connections: 2 目前有 2 個活動連線。\n* server accepts handled requests: 2 2 2 - **2**：已接受的連線數。 - **2**：已成功處理的連線數。 - **2**：總請求數（可能大於連線數，因為每個連線可以處理多個請求）。 * Reading: 0 Writing: 1 Waiting: 1 - Reading: 0：正在讀取請求的連線數。 - Writing: 1：正在傳送響應的連線數。 - Waiting: 1：空閒等待新請求的連線數（使用 HTTP Keep-Alive）。 P.S.當前伺服器負載較輕，共有 2 個連線，其中 1 個正在處理請求，1 個處於等待新請求的狀態。 檢查 nginx-prometheus-exporter 收集的指標 http://localhost:9113/metrics 檢查 node exporter 收集的主機指標 http://localhost:9100/metrics 在 Prometheus 檢查端點狀態 點擊 http://localhost:9090/ 檢查 Prometheus 是否正在運行。 我們可以輸入 up 來查詢當前存活的端點。\n我們可以輸入 target 來查詢當前存活的端點。 http://localhost:9090/targets 現在，指標已被 Prometheus 收集並重新導向。\n視覺化輸出 (Visualization output) 接下來，我們使用 Grafana 來建立視覺化資料。 前往 http://localhost:3000/ Select Data Source Click Test to test the connectivity between Prometheus and Grafana. Then, we go to Dashboards and select New -\u0026gt; New dashboard. We see the following page and select import dashboard to create new dashboard\n官網上也有很多dashboard template. 這邊我使用 Node exporter ID 1860 跟Nginx exporter ID 14900.\nDashboards\nfor nginx: https://grafana.com/grafana/dashboards/12708 for node exporter : https://grafana.com/grafana/dashboards/1860 We select load Also, select Prometheus data source and click import Once the dashboard is created, we can see the list of dashboards. Dashboard for Host Dashboard for Nginx Now, we have visualized data for monitor.\nTo generate traffic, we can use k6_script\ncat k6_script.js| docker run --rm -i grafana/k6 run - Conclusion In this article, we demonstrate\nUsing Prometheus to collect and monitor our host machine and Nginx service. The collected metric information is further visualized in Grafana Reference https://last9.hashnode.dev/how-to-download-and-run-node-exporter-using-docker#heading-step-2-run-the-node-exporter-container\nhttps://github.com/880831ian/Prometheus-Grafana-Docker\nhttps://mxulises.medium.com/simple-prometheus-setup-on-docker-compose-f702d5f98579\nhttps://github.com/880831ian/Prometheus-Grafana-Docker/tree/master\n","permalink":"https://nikeasyanzi.github.io/tw/posts/visualized-monitoring-with-prometheus-grafana/","summary":"\u003ch1 id=\"簡介-introduction\"\u003e簡介 (Introduction)\u003c/h1\u003e\n\u003cp\u003e在本文中，我們將展示\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e如何使用 Prometheus 來收集和監控我們的主機與 Nginx 服務。\u003c/li\u003e\n\u003cli\u003e在 Grafana 中視覺化呈現收集到的指標\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch1 id=\"元件-components\"\u003e元件 (Components)\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePrometheus\u003c/strong\u003e 收集並儲存時間序列資料形式的指標，亦即指標資訊會與記錄時的時間戳記一起儲存，以及稱為標籤的選用鍵值對。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePrometheus node exporter\u003c/strong\u003e 公開各種與硬體和核心相關的指標。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGrafana\u003c/strong\u003e 一種圖形化處理軟體，可支援不同型式的來源資料數據，並以豐富的圖形來呈現相關數據\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"配置-configuration\"\u003e配置 (Configuration)\u003c/h1\u003e\n\u003ch2 id=\"更新-docker-compose\"\u003e更新 docker-compose\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eservices\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003enginx\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eimage\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003enginx:latest\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003econtainer_name\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003enginx\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003evolumes\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003e./nginx/:/etc/nginx/conf.d\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eports\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003e8082\u003c/span\u003e:\u003cspan style=\"color:#ae81ff\"\u003e8080\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003enginx-prometheus-exporter\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eimage\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003enginx/nginx-prometheus-exporter:1.4\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003econtainer_name\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003enginx-prometheus-exporter\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003ecommand\u003c/span\u003e: -\u003cspan style=\"color:#ae81ff\"\u003enginx.scrape-uri http://nginx:8080/stub_status\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eports\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003e9113\u003c/span\u003e:\u003cspan style=\"color:#ae81ff\"\u003e9113\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003edepends_on\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003enginx\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#75715e\"\u003e# System monitoring\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003enode-exporter\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003econtainer_name\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003enode-exporter\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eimage\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003eprom/node-exporter\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eports\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003e9100\u003c/span\u003e:\u003cspan style=\"color:#ae81ff\"\u003e9100\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003eprometheus\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eimage\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003eprom/prometheus:latest\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003econtainer_name\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003eprometheus\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003evolumes\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003e./prometheus.yaml:/etc/prometheus/prometheus.yaml\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003e./prometheus_data:/prometheus\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003ecommand\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;--config.file=/etc/prometheus/prometheus.yaml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eports\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;9090:9090\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003edepends_on\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003enode-exporter\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003enginx-prometheus-exporter\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#75715e\"\u003e#handles rendering panels \u0026amp; dashboards to PNGs\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003erenderer\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eimage\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003egrafana/grafana-image-renderer:3.4.2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eenvironment\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      \u003cspan style=\"color:#f92672\"\u003eBROWSER_TZ\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003eAsia/Taipei\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eports\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;8081:8081\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003egrafana\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eimage\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003egrafana/grafana:latest\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003econtainer_name\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003egrafana\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003evolumes\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003e./grafana_data:/var/lib/grafana\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eenvironment\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      \u003cspan style=\"color:#f92672\"\u003eGF_SECURITY_ADMIN_PASSWORD\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003epass\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      \u003cspan style=\"color:#f92672\"\u003eGF_RENDERING_SERVER_URL\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003ehttp://renderer:8081/render\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      \u003cspan style=\"color:#f92672\"\u003eGF_RENDERING_CALLBACK_URL\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003ehttp://grafana:3000/\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      \u003cspan style=\"color:#f92672\"\u003eGF_LOG_FILTERS\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003erendering:debug\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003edepends_on\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003eprometheus\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eports\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;3000:3000\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"更新-prometheusyaml\"\u003e更新 prometheus.yaml\u003c/h2\u003e\n\u003cp\u003e配置 Prometheus 抓取間隔\u003c/p\u003e","title":"使用 Prometheus 和 Grafana 進行視覺化監控"},{"content":"Steps 1. 創建 Docker Compose 檔案 首先，建立一個專案目錄用來存放 n8n 的相關檔案。在終端機中執行以下命令：\nmkdir n8n-dockercd n8n-docker 在專案目錄中創建一個 docker-compose.yml 檔案，用來定義 n8n 和 PostgreSQL 的 Docker 容器。\ndocker-compose.yml\nservices: n8n: image: n8nio/n8n:nightly ports: - \u0026#34;5678:5678\u0026#34; environment: - DB_TYPE=postgresdb - DB_POSTGRESDB_HOST=postgres - DB_POSTGRESDB_DATABASE=${POSTGRES_DB} - DB_POSTGRESDB_USER=${POSTGRES_USER} - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD} volumes: - ./n8n_storage:/home/node/.n8n depends_on: - postgres postgres: image: postgres:13.22-alpine3.22 environment: - POSTGRES_USER=${POSTGRES_USER} - POSTGRES_PASSWORD=${POSTGRES_PASSWORD} - POSTGRES_DB=${POSTGRES_DB} volumes: - ./postgres_storage:/var/lib/postgresql/data volumes: n8n_storage: postgres_storage: 說明：\n使用 n8n 的 Docker 映像檔，並將容器的 5678 埠映射到主機的 5678 埠。 postgres 服務：使用 PostgreSQL 的 Docker 映像檔，並設定用戶名、密碼和資料庫名稱(放在 .env 檔案中)。 volumes：分別用來保存 n8n 和 PostgreSQL 的資料。 GENERIC_TIMEZONE 和 TZ 環境變數：設定時區為台北時區。 相關設定可以參考 n8n 官方文件。 2. 創建 .env 檔案 在專案目錄中創建一個 .env 檔案，用來設定 PostgreSQL 的用戶名、密碼和資料庫名稱。 根據 docker official document, the .env will be treated as env variable file\nPOSTGRES_USER=your_username POSTGRES_PASSWORD=your_password POSTGRES_DB=your_n8n_database 3. 啟動 n8n 服務 在終端機中執行以下命令，啟動 n8n 和 PostgreSQL 服務：你應該會看到建立的容器正在背景運行。\ndocker compose up -d 我們可以確認一下postgres 的log\ndocker logs n8n-postgres-1 4. 打開瀏覽器前往 n8n 頁面 http://localhost:5678 Reference https://darrenjon.com/docs/n8n/n8n-docker-setup/\n","permalink":"https://nikeasyanzi.github.io/tw/posts/self-hosting-n8n-with-docker/","summary":"\u003ch1 id=\"steps\"\u003eSteps\u003c/h1\u003e\n\u003ch2 id=\"1-創建-docker-compose-檔案\"\u003e1. 創建 Docker Compose 檔案\u003c/h2\u003e\n\u003cp\u003e首先，建立一個專案目錄用來存放 n8n 的相關檔案。在終端機中執行以下命令：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003emkdir n8n-dockercd n8n-docker\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e在專案目錄中創建一個 \u003ccode\u003edocker-compose.yml\u003c/code\u003e 檔案，用來定義 n8n 和 PostgreSQL 的 Docker 容器。\u003c/p\u003e\n\u003cp\u003edocker-compose.yml\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eservices\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003en8n\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eimage\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003en8nio/n8n:nightly\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eports\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;5678:5678\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eenvironment\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003eDB_TYPE=postgresdb\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003eDB_POSTGRESDB_HOST=postgres\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003eDB_POSTGRESDB_DATABASE=${POSTGRES_DB}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003eDB_POSTGRESDB_USER=${POSTGRES_USER}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003eDB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003evolumes\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003e./n8n_storage:/home/node/.n8n\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003edepends_on\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003epostgres\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003epostgres\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eimage\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003epostgres:13.22-alpine3.22\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003eenvironment\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003ePOSTGRES_USER=${POSTGRES_USER}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003ePOSTGRES_PASSWORD=${POSTGRES_PASSWORD}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003ePOSTGRES_DB=${POSTGRES_DB}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003evolumes\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e      - \u003cspan style=\"color:#ae81ff\"\u003e./postgres_storage:/var/lib/postgresql/data\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003evolumes\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003en8n_storage\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003epostgres_storage\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e說明：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e使用 n8n 的 Docker 映像檔，並將容器的 \u003ccode\u003e5678\u003c/code\u003e 埠映射到主機的 \u003ccode\u003e5678\u003c/code\u003e 埠。\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003epostgres\u003c/code\u003e 服務：使用 PostgreSQL 的 Docker 映像檔，並設定用戶名、密碼和資料庫名稱(放在 \u003ccode\u003e.env\u003c/code\u003e 檔案中)。\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003evolumes\u003c/code\u003e：分別用來保存 n8n 和 PostgreSQL 的資料。\u003c/li\u003e\n\u003cli\u003eGENERIC_TIMEZONE 和 TZ 環境變數：設定時區為台北時區。\u003c/li\u003e\n\u003cli\u003e相關設定可以參考 \u003ca href=\"https://docs.n8n.io/hosting/installation/docker\"\u003en8n 官方文件\u003c/a\u003e。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"2-創建env檔案\"\u003e2. 創建 \u003ccode\u003e.env\u003c/code\u003e 檔案\u003c/h2\u003e\n\u003cp\u003e在專案目錄中創建一個 \u003ccode\u003e.env\u003c/code\u003e 檔案，用來設定 PostgreSQL 的用戶名、密碼和資料庫名稱。\n根據 \u003ca href=\"https://docs.docker.com/compose/how-tos/environment-variables/set-environment-variables/\"\u003edocker official document\u003c/a\u003e, the \u003cstrong\u003e.env\u003c/strong\u003e will be treated as env variable file\u003c/p\u003e","title":"Self hosting local n8n service"},{"content":"簡介 (Intro) 透過 ollama 和 Open WebUI，自架類似 ChatGPT 的服務已成為可能。對於關注與 AI 服務供應商分享資料問題的個人或企業來說，這絕對是個好消息。 在本文中，我將展示如何在本地環境中設置此服務。\n步驟 (Steps) 首先，我們需要設置 2 個服務，並將這些服務架設在容器上。\n拉取 ollama container image docker pull ollama/ollama:latest 在執行服務之前，我們需要從 ollama model 下載模型。作為實驗，我們選擇 llama3.2。 docker exec 5eeaf ollama pull llama3.2 這裡我選擇了 llama3.2 模型。下載需要一些時間，取決於網路速度和所選模型的大小。 執行 ollama 服務 docker run -d -v $(PWD):/root/.ollama -p 11434:11434 --name ollama ollama/ollama 拉取 Open Web UI 映像檔 docker pull ghcr.io/open-webui/open-webui:latest 我們建立一個名為 open-webui 的資料夾。現在，目錄結構如下所示。 我們可以看到已下載的 llama3.2 模型以及新建立的 open-webui 資料夾，用於存放 Open Web UI 資料。 執行 Open Web UI 映像檔 docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v ./open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main 容器需要一些時間才能準備好運作。當狀態顯示為 healthy 時，我們可以嘗試開啟 http://localhost:3000 首次登入時，我們需要註冊一個新帳號 成功登入後，我們可以看到 llama3.2 已被選取，現在可以開始使用了。 使用 Docker Compose 整合服務 我也撰寫了一個 Docker Compose 檔案，這樣我們就可以一鍵部署服務。請參考： https://github.com/nikeasyanzi/my-toolbox/tree/main/ollama_openwebui\n","permalink":"https://nikeasyanzi.github.io/tw/posts/self-hosting-chatgpt-in-a-minute/","summary":"\u003ch1 id=\"簡介-intro\"\u003e簡介 (Intro)\u003c/h1\u003e\n\u003cp\u003e透過 \u003ca href=\"https://ollama.com/\"\u003eollama\u003c/a\u003e 和 \u003ca href=\"https://github.com/open-webui/open-webui\"\u003eOpen WebUI\u003c/a\u003e，自架類似 ChatGPT 的服務已成為可能。對於關注與 AI 服務供應商分享資料問題的個人或企業來說，這絕對是個好消息。\n在本文中，我將展示如何在本地環境中設置此服務。\u003c/p\u003e\n\u003ch1 id=\"步驟-steps\"\u003e步驟 (Steps)\u003c/h1\u003e\n\u003cp\u003e首先，我們需要設置 2 個服務，並將這些服務架設在容器上。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e拉取 \u003ca href=\"https://hub.docker.com/r/ollama/ollama\"\u003eollama container image\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-bash=\" data-lang=\"bash=\"\u003edocker pull ollama/ollama:latest\n\u003c/code\u003e\u003c/pre\u003e\u003col start=\"2\"\u003e\n\u003cli\u003e在執行服務之前，我們需要從 \u003ca href=\"https://ollama.com/models\"\u003eollama model\u003c/a\u003e 下載模型。作為實驗，我們選擇 llama3.2。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://i.imgur.com/iwluBge.png\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://i.imgur.com/lnBbjDQ.png\"\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-bash=\" data-lang=\"bash=\"\u003edocker exec 5eeaf ollama pull llama3.2\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e這裡我選擇了 llama3.2 模型。下載需要一些時間，取決於網路速度和所選模型的大小。\n\u003cimg loading=\"lazy\" src=\"https://i.imgur.com/DfxrHZv.png\"\u003e\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e執行 ollama 服務\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-bash=\" data-lang=\"bash=\"\u003edocker run -d -v $(PWD):/root/.ollama -p 11434:11434 --name ollama ollama/ollama\n\u003c/code\u003e\u003c/pre\u003e\u003col start=\"4\"\u003e\n\u003cli\u003e拉取 Open Web UI 映像檔\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-bash=\" data-lang=\"bash=\"\u003edocker pull ghcr.io/open-webui/open-webui:latest\n\u003c/code\u003e\u003c/pre\u003e\u003col start=\"5\"\u003e\n\u003cli\u003e我們建立一個名為 open-webui 的資料夾。現在，目錄結構如下所示。\n我們可以看到已下載的 llama3.2 模型以及新建立的 open-webui 資料夾，用於存放 Open Web UI 資料。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://i.imgur.com/OBRCjpR.png\"\u003e\u003c/p\u003e","title":"使用 Ollama 和 Open WebUI 在一分鐘內自架本地 AI"},{"content":"管理 Python 套件一直是個令人頭痛的問題。但當我遇到 UV 後，我覺得自己得救了。\n簡介 (Introduction) Python 套件管理問題主要有兩個考量：\nPython 版本：不同專案可能需要不同的 Python 直譯器。沒有人想把它們與系統預設的 Python 直譯器混在一起。\n專案所需的套件／函式庫：直覺上，不同專案有不同的函式庫相依性。即使它們都依賴像 OpenSSL 這樣的熱門函式庫，也可能依賴不同的函式庫版本。\n有些工具嘗試解決這個問題。 例如：\nvenv 和 pip 提供套件管理，但無法在不同 Python 版本之間切換。\nPyenv 解決了 Python 版本切換問題，但不支援套件管理。\nUV 的開發目標就是解決上述問題。\n在這裡，我將逐步介紹如何使用 uv 來管理你的專案。\n實作演練 (Walkthrough) 安裝 (Installation) 對於 macOS 和 Linux，我會使用\ncurl -LsSf https://astral.sh/uv/install.sh | sh or through brew for macOS\nbrew install uv Important files The are some key files for UV to manage the project dependency. In addition, the good news is UV automatically generates and updates these files. Let\u0026rsquo;s take a quick look.\n.python-version: contains the Python version used for the project\npyproject.toml: serves as the main configuration file for project metadata and dependencies.\nuv.lock: Lock files for dependency management in UV.\nInitialization $ uv init my-uv Initialized project `my-uv` at `/Users/craigyang/workplace/my-uv` $ cd my-uv $ tree -a -L 1 . ├── .git ├── .gitignore ├── .python-version ├── main.py ├── pyproject.toml └── README.md 2 directories, 5 files 使用 UV 執行 Python 腳本 (Running Python scripts with UV) 讓我們看一下 main.py\n$ cat main.py def main(): print(\u0026#34;Hello from my-uv!\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() 執行 main.py 時，虛擬環境會自動建立。\n$ uv run main.py Using CPython 3.13.4 Creating virtual environment at: .venv Hello from my-uv! 更新相依性 (Updating dependencies) 在這裡，我們使用 requests 作為要新增的新函式庫。我們可以看到 pyproject.toml 的內容也被更新了。\n$ uv add requests Resolved 6 packages in 605ms Prepared 2 packages in 223ms Installed 5 packages in 10ms + certifi==2025.4.26 + charset-normalizer==3.4.2 + idna==3.10 + requests==2.32.4 + urllib3==2.4.0 $ cat pyproject.toml [project] name = \u0026#34;my-uv\u0026#34; version = \u0026#34;0.1.0\u0026#34; description = \u0026#34;Add your description here\u0026#34; readme = \u0026#34;README.md\u0026#34; requires-python = \u0026#34;\u0026gt;=3.13\u0026#34; dependencies = [ \u0026#34;requests\u0026gt;=2.32.4\u0026#34;, ] 在 UV 中管理 Python 版本 (Managing Python Versions in UV) 在以下提示中，我們看到對於 my-uv 專案，Python3.13 是預設選項，而在系統中安裝的是 Python3.9.6\n$ uv python list cpython-3.14.0b1-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.14.0b1+freethreaded-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.13.4-macos-aarch64-none /opt/homebrew/bin/python3.13 -\u0026gt; ../Cellar/python@3.13/3.13.4/bin/python3.13 cpython-3.13.4-macos-aarch64-none /opt/homebrew/bin/python3 -\u0026gt; ../Cellar/python@3.13/3.13.4/bin/python3 cpython-3.13.4-macos-aarch64-none /Users/craigyang/.local/share/uv/python/cpython-3.13.4-macos-aarch64-none/bin/python3.13 cpython-3.13.4+freethreaded-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.12.11-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.11.13-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.10.18-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.9.23-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.9.6-macos-aarch64-none /usr/bin/python3 在 UV 中匯出 requirements (Export requirements in UV) uv export -o requirements.txt 結論 (Conclusion) 我們已經展示了如何使用 uv 來開始一個新專案。 我也推薦這篇關於 uv 的完整文章給對此主題有興趣的人。\n","permalink":"https://nikeasyanzi.github.io/tw/posts/uv/","summary":"\u003cp\u003e管理 Python 套件一直是個令人頭痛的問題。但當我遇到 \u003ca href=\"https://github.com/astral-sh/uv\"\u003eUV\u003c/a\u003e 後，我覺得自己得救了。\u003c/p\u003e\n\u003ch2 id=\"簡介-introduction\"\u003e簡介 (Introduction)\u003c/h2\u003e\n\u003cp\u003ePython 套件管理問題主要有兩個考量：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ePython 版本：不同專案可能需要不同的 Python 直譯器。沒有人想把它們與系統預設的 Python 直譯器混在一起。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e專案所需的套件／函式庫：直覺上，不同專案有不同的函式庫相依性。即使它們都依賴像 OpenSSL 這樣的熱門函式庫，也可能依賴不同的函式庫版本。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e有些工具嘗試解決這個問題。\n例如：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://docs.python.org/3/library/venv.html\"\u003evenv\u003c/a\u003e 和 \u003ca href=\"https://github.com/pypa/pip\"\u003epip\u003c/a\u003e 提供套件管理，但無法在不同 Python 版本之間切換。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/pyenv/pyenv\"\u003ePyenv\u003c/a\u003e 解決了 Python 版本切換問題，但不支援套件管理。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/astral-sh/uv\"\u003eUV\u003c/a\u003e 的開發目標就是解決上述問題。\u003c/p\u003e\n\u003cp\u003e在這裡，我將逐步介紹如何使用 \u003cstrong\u003euv\u003c/strong\u003e 來管理你的專案。\u003c/p\u003e\n\u003ch2 id=\"實作演練-walkthrough\"\u003e實作演練 (Walkthrough)\u003c/h2\u003e\n\u003ch4 id=\"安裝-installation\"\u003e安裝 (Installation)\u003c/h4\u003e\n\u003cp\u003e對於 macOS 和 Linux，我會使用\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecurl -LsSf https://astral.sh/uv/install.sh | sh\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eor through \u003cstrong\u003ebrew\u003c/strong\u003e for macOS\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ebrew install uv\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"important-files\"\u003eImportant files\u003c/h4\u003e\n\u003cp\u003eThe are some key files for UV to manage the project dependency.\nIn addition, the good news is UV automatically generates and updates these files. Let\u0026rsquo;s take a quick look.\u003c/p\u003e","title":"UV：Python 套件管理工具"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code Code Blocks Inline Code This is Inline Code\nOnly pre Code block with backticks \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with backticks and language specified 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;description\u0026#34; content=\u0026#34;Sample article showcasing basic Markdown syntax and formatting for HTML elements.\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://nikeasyanzi.github.io/tw/posts/markdown-syntax/","summary":"\u003cp\u003eThis article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\u003c/p\u003e","title":"Markdown Syntax Guide"},{"content":"I am a software engineer from Taiwan. Mainly focus on Linux, and Self hosting.\n","permalink":"https://nikeasyanzi.github.io/tw/about/","summary":"\u003cp\u003eI am a software engineer from Taiwan. Mainly focus on Linux, and Self hosting.\u003c/p\u003e","title":"About Me"}]