[{"content":"Intro With ollama and Open WebUI, self-hosting a chatgpt like service is possible. It\u0026rsquo;s definitely a great news for people or corporations concerning about sharing their data with AI service providers. In this article, I will show you how to setup a service in local environment.\nSteps First of all, there are 2 services we need to setup, and we will host the service on container.\nPull ollama container image docker pull ollama/ollama:latest Before we run the service, we need to download a model from ollama model. For experiment, we select llama3.2. docker exec 5eeaf ollama pull llama3.2 Here, I select model llama3.2. It takes a while to download depends on the network and size of selected model.\nRun ollama service docker run -d -v $(PWD):/root/.ollama -p 11434:11434 --name ollama ollama/ollama Pull Open Web UI image docker pull ghcr.io/open-webui/open-webui:latest We create a folder named open-webui. Now, the directory lay out looks like the following. We see the downloaded llama3.2 model and the new created open-webui folder for Open Web UI data placement.. Run Open Web UI image docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v ./open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main It would takes a while to get the container ready to work. Once, the status shows healthy, we can try to open http://localhost:3000 For first time login, we will need to register a new account Once we log in with success, we can see the llama3.2 is selected and we can start to play with it. Docker compose with service I also write up a docker compose file, so we can host the file with one click. Check it out. https://github.com/nikeasyanzi/my-toolbox/tree/main/ollama_openwebui\n","permalink":"https://nikeasyanzi.github.io/posts/self-hosting-chatgpt-in-a-minute/","summary":"\u003ch1 id=\"intro\"\u003eIntro\u003c/h1\u003e\n\u003cp\u003eWith \u003ca href=\"https://ollama.com/\"\u003eollama\u003c/a\u003e and \u003ca href=\"https://github.com/open-webui/open-webui\"\u003eOpen WebUI\u003c/a\u003e, self-hosting a chatgpt like service is possible. It\u0026rsquo;s definitely a great news for people or corporations concerning about sharing their data with AI service providers.\nIn this article, I will show you how to setup a service in local environment.\u003c/p\u003e\n\u003ch1 id=\"steps\"\u003eSteps\u003c/h1\u003e\n\u003cp\u003eFirst of all, there are 2 services we need to setup, and we will host the service on container.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ePull \u003ca href=\"https://hub.docker.com/r/ollama/ollama\"\u003eollama container image\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-bash=\" data-lang=\"bash=\"\u003edocker pull ollama/ollama:latest\n\u003c/code\u003e\u003c/pre\u003e\u003col start=\"2\"\u003e\n\u003cli\u003eBefore we run the service, we need to download a model from \u003ca href=\"https://ollama.com/models\"\u003eollama model\u003c/a\u003e. For experiment, we select llama3.2.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\n  \u003cimg loading=\"lazy\" src=\"https://i.imgur.com/iwluBge.png\" alt=\"\"  /\u003e\u003c/p\u003e","title":"Self hosting a local AI in a minute with Ollama and Open WebUI"},{"content":"It\u0026rsquo;s been a headache to manage Python packages. But I feel I am saved from that when I meet UV.\nIntroduction There are two main concerns related to the Python package management problem.\nPython version: Different projects may need different Python interpreters. No one wants to mix them with the system default Python interpreters.\nThe packages/libraries needed by the project: Intuitively, different projects have different library dependencies. Even if they all rely on a popular library such as OpenSSL, they may depend on different library versions.\nSome tools are trying to solve the problem. For example,\nvenv and pip provide package management but are unable to switch between different versions of Python.\nPyenv solves the Python version switching problem but does not support package management.\nUV is developed and aimed at solving the aforementioned issues.\nHere, I walk through how to use uv to manage your project.\nWalkthrough Installation For macOS and Linux. I would use\ncurl -LsSf https://astral.sh/uv/install.sh | sh or through brew for macOS\nbrew install uv Important files The are some key files for UV to manage the project dependency. In addition, the good news is UV automatically generates and updates these files. Let\u0026rsquo;s take a quick look.\n.python-version: contains the Python version used for the project\npyproject.toml: serves as the main configuration file for project metadata and dependencies.\nuv.lock: Lock files for dependency management in UV.\nInitialization $ uv init my-uv Initialized project `my-uv` at `/Users/craigyang/workplace/my-uv` $ cd my-uv $ tree -a -L 1 . ├── .git ├── .gitignore ├── .python-version ├── main.py ├── pyproject.toml └── README.md 2 directories, 5 files Running Python scripts with UV Let\u0026rsquo;s take a look on the main.py\n$ cat main.py def main(): print(\u0026#34;Hello from my-uv!\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() While executing the main.py, a virtual environment is created automatically.\n$ uv run main.py Using CPython 3.13.4 Creating virtual environment at: .venv Hello from my-uv! Updating dependencies Here, we use requests as a new library to be added. We can see the content pyproject.toml is also updated.\n$ uv add requests Resolved 6 packages in 605ms Prepared 2 packages in 223ms Installed 5 packages in 10ms + certifi==2025.4.26 + charset-normalizer==3.4.2 + idna==3.10 + requests==2.32.4 + urllib3==2.4.0 $ cat pyproject.toml [project] name = \u0026#34;my-uv\u0026#34; version = \u0026#34;0.1.0\u0026#34; description = \u0026#34;Add your description here\u0026#34; readme = \u0026#34;README.md\u0026#34; requires-python = \u0026#34;\u0026gt;=3.13\u0026#34; dependencies = [ \u0026#34;requests\u0026gt;=2.32.4\u0026#34;, ] Managing Python Versions in UV In the following prompt, we see that for the my-uv project, Python3.13 is the default option, while in the system, it is installed with Python3.9.6\n$ uv python list cpython-3.14.0b1-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.14.0b1+freethreaded-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.13.4-macos-aarch64-none /opt/homebrew/bin/python3.13 -\u0026gt; ../Cellar/python@3.13/3.13.4/bin/python3.13 cpython-3.13.4-macos-aarch64-none /opt/homebrew/bin/python3 -\u0026gt; ../Cellar/python@3.13/3.13.4/bin/python3 cpython-3.13.4-macos-aarch64-none /Users/craigyang/.local/share/uv/python/cpython-3.13.4-macos-aarch64-none/bin/python3.13 cpython-3.13.4+freethreaded-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.12.11-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.11.13-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.10.18-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.9.23-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.9.6-macos-aarch64-none /usr/bin/python3 Export requirements in UV uv export -o requirements.txt Conclusion We have shown how to use uv to start a new project. I also recommend a comprehensive article about uv for people interest in this topic.\n","permalink":"https://nikeasyanzi.github.io/posts/uv/","summary":"\u003cp\u003eIt\u0026rsquo;s been a headache to manage Python packages. But I feel I am saved from that when I meet \u003ca href=\"https://github.com/astral-sh/uv\"\u003eUV\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eThere are two main concerns related to the Python package management problem.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ePython version: Different projects may need different Python interpreters. No one wants to mix them with the system default Python interpreters.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe packages/libraries needed by the project: Intuitively, different projects have different library dependencies. Even if they all rely on a popular library such as OpenSSL, they may depend on different library versions.\u003c/p\u003e","title":"UV: A Python Package Management Tool"}]