[{"content":"Intro With ollama and Open WebUI, self-hosting a chatgpt like service is possible. It\u0026rsquo;s definitely a great news for people or corporations concerning about sharing their data with AI service providers. In this article, I will show you how to setup a service in local environment.\nSteps First of all, there are 2 services we need to setup, and we will host the service on container.\nPull ollama container image 1 docker pull ollama/ollama:latest Before we run the service, we need to download a model from ollama model. For experiment, we select llama3.2. 1 docker exec 5eeaf ollama pull llama3.2 Here, I select model llama3.2. It takes a while to download depends on the network and size of selected model.\nRun ollama service 1 docker run -d -v $(PWD):/root/.ollama -p 11434:11434 --name ollama ollama/ollama Pull Open Web UI image 1 docker pull ghcr.io/open-webui/open-webui:latest We create a folder named open-webui. Now, the directory lay out looks like the following. We see the downloaded llama3.2 model and the new created open-webui folder for Open Web UI data placement.. Run Open Web UI image 1 docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v ./open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main It would takes a while to get the container ready to work. Once, the status shows healthy, we can try to open http://localhost:3000 For first time login, we will need to register a new account Once we log in with success, we can see the llama3.2 is selected and we can start to play with it. Docker compose with service I also write up a docker compose file, so we can host the file with one click. Check it out. https://github.com/nikeasyanzi/my-toolbox/tree/main/ollama_openwebui\n","permalink":"https://nikeasyanzi.github.io/posts/self-hosting-chatgpt-in-a-minute/","summary":"\u003ch1 id=\"intro\"\u003eIntro\u003c/h1\u003e\n\u003cp\u003eWith \u003ca href=\"https://ollama.com/\"\u003eollama\u003c/a\u003e and \u003ca href=\"https://github.com/open-webui/open-webui\"\u003eOpen WebUI\u003c/a\u003e, self-hosting a chatgpt like service is possible. It\u0026rsquo;s definitely a great news for people or corporations concerning about sharing their data with AI service providers.\nIn this article, I will show you how to setup a service in local environment.\u003c/p\u003e\n\u003ch1 id=\"steps\"\u003eSteps\u003c/h1\u003e\n\u003cp\u003eFirst of all, there are 2 services we need to setup, and we will host the service on container.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ePull \u003ca href=\"https://hub.docker.com/r/ollama/ollama\"\u003eollama container image\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003edocker pull ollama/ollama:latest\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003col start=\"2\"\u003e\n\u003cli\u003eBefore we run the service, we need to download a model from \u003ca href=\"https://ollama.com/models\"\u003eollama model\u003c/a\u003e. For experiment, we select llama3.2.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\n  \u003cimg loading=\"lazy\" src=\"https://i.imgur.com/iwluBge.png\" alt=\"\"  /\u003e\u003c/p\u003e","title":"Self hosting a local AI in a minute with Ollama and Open WebUI"},{"content":"Steps 1. 創建 Docker Compose 檔案 首先，建立一個專案目錄用來存放 n8n 的相關檔案。在終端機中執行以下命令：\n1 mkdir n8n-dockercd n8n-docker 在專案目錄中創建一個 docker-compose.yml 檔案，用來定義 n8n 和 PostgreSQL 的 Docker 容器。\ndocker-compose.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 services: n8n: image: n8nio/n8n:nightly ports: - \u0026#34;5678:5678\u0026#34; environment: - DB_TYPE=postgresdb - DB_POSTGRESDB_HOST=postgres - DB_POSTGRESDB_DATABASE=${POSTGRES_DB} - DB_POSTGRESDB_USER=${POSTGRES_USER} - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD} volumes: - ./n8n_storage:/home/node/.n8n depends_on: - postgres postgres: image: postgres:13.22-alpine3.22 environment: - POSTGRES_USER=${POSTGRES_USER} - POSTGRES_PASSWORD=${POSTGRES_PASSWORD} - POSTGRES_DB=${POSTGRES_DB} volumes: - ./postgres_storage:/var/lib/postgresql/data volumes: n8n_storage: postgres_storage: 說明：\n使用 n8n 的 Docker 映像檔，並將容器的 5678 埠映射到主機的 5678 埠。 postgres 服務：使用 PostgreSQL 的 Docker 映像檔，並設定用戶名、密碼和資料庫名稱(放在 .env 檔案中)。 volumes：分別用來保存 n8n 和 PostgreSQL 的資料。 GENERIC_TIMEZONE 和 TZ 環境變數：設定時區為台北時區。 相關設定可以參考 n8n 官方文件。 2. 創建 .env 檔案 在專案目錄中創建一個 .env 檔案，用來設定 PostgreSQL 的用戶名、密碼和資料庫名稱。 根據 docker official document, the .env will be treated as env variable file\n1 2 3 POSTGRES_USER=your_username POSTGRES_PASSWORD=your_password POSTGRES_DB=your_n8n_database 3. 啟動 n8n 服務 在終端機中執行以下命令，啟動 n8n 和 PostgreSQL 服務：你應該會看到建立的容器正在背景運行。\n1 docker compose up -d 我們可以確認一下postgres 的log\n1 docker logs n8n-postgres-1 4. 打開瀏覽器前往 n8n 頁面 http://localhost:5678 Reference https://darrenjon.com/docs/n8n/n8n-docker-setup/\n","permalink":"https://nikeasyanzi.github.io/posts/self-hosting-n8n-with-docker/","summary":"\u003ch1 id=\"steps\"\u003eSteps\u003c/h1\u003e\n\u003ch2 id=\"1-創建-docker-compose-檔案\"\u003e1. 創建 Docker Compose 檔案\u003c/h2\u003e\n\u003cp\u003e首先，建立一個專案目錄用來存放 n8n 的相關檔案。在終端機中執行以下命令：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emkdir n8n-dockercd n8n-docker\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e在專案目錄中創建一個 \u003ccode\u003edocker-compose.yml\u003c/code\u003e 檔案，用來定義 n8n 和 PostgreSQL 的 Docker 容器。\u003c/p\u003e","title":"Self hosting a local AI in a minute with Ollama and Open WebUI"},{"content":"It\u0026rsquo;s been a headache to manage Python packages. But I feel I am saved from that when I meet UV.\nIntroduction There are two main concerns related to the Python package management problem.\nPython version: Different projects may need different Python interpreters. No one wants to mix them with the system default Python interpreters.\nThe packages/libraries needed by the project: Intuitively, different projects have different library dependencies. Even if they all rely on a popular library such as OpenSSL, they may depend on different library versions.\nSome tools are trying to solve the problem. For example,\nvenv and pip provide package management but are unable to switch between different versions of Python.\nPyenv solves the Python version switching problem but does not support package management.\nUV is developed and aimed at solving the aforementioned issues.\nHere, I walk through how to use uv to manage your project.\nWalkthrough Installation For macOS and Linux. I would use\n1 curl -LsSf https://astral.sh/uv/install.sh | sh or through brew for macOS\n1 brew install uv Important files The are some key files for UV to manage the project dependency. In addition, the good news is UV automatically generates and updates these files. Let\u0026rsquo;s take a quick look.\n.python-version: contains the Python version used for the project\npyproject.toml: serves as the main configuration file for project metadata and dependencies.\nuv.lock: Lock files for dependency management in UV.\nInitialization 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ uv init my-uv Initialized project `my-uv` at `/Users/craigyang/workplace/my-uv` $ cd my-uv $ tree -a -L 1 . ├── .git ├── .gitignore ├── .python-version ├── main.py ├── pyproject.toml └── README.md 2 directories, 5 files Running Python scripts with UV Let\u0026rsquo;s take a look on the main.py\n1 2 3 4 5 6 7 $ cat main.py def main(): print(\u0026#34;Hello from my-uv!\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() While executing the main.py, a virtual environment is created automatically.\n1 2 3 4 $ uv run main.py Using CPython 3.13.4 Creating virtual environment at: .venv Hello from my-uv! Updating dependencies Here, we use requests as a new library to be added. We can see the content pyproject.toml is also updated.\n1 2 3 4 5 6 7 8 9 $ uv add requests Resolved 6 packages in 605ms Prepared 2 packages in 223ms Installed 5 packages in 10ms + certifi==2025.4.26 + charset-normalizer==3.4.2 + idna==3.10 + requests==2.32.4 + urllib3==2.4.0 1 2 3 4 5 6 7 8 9 10 $ cat pyproject.toml [project] name = \u0026#34;my-uv\u0026#34; version = \u0026#34;0.1.0\u0026#34; description = \u0026#34;Add your description here\u0026#34; readme = \u0026#34;README.md\u0026#34; requires-python = \u0026#34;\u0026gt;=3.13\u0026#34; dependencies = [ \u0026#34;requests\u0026gt;=2.32.4\u0026#34;, ] Managing Python Versions in UV In the following prompt, we see that for the my-uv project, Python3.13 is the default option, while in the system, it is installed with Python3.9.6\n1 2 3 4 5 6 7 8 9 10 11 12 $ uv python list cpython-3.14.0b1-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.14.0b1+freethreaded-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.13.4-macos-aarch64-none /opt/homebrew/bin/python3.13 -\u0026gt; ../Cellar/python@3.13/3.13.4/bin/python3.13 cpython-3.13.4-macos-aarch64-none /opt/homebrew/bin/python3 -\u0026gt; ../Cellar/python@3.13/3.13.4/bin/python3 cpython-3.13.4-macos-aarch64-none /Users/craigyang/.local/share/uv/python/cpython-3.13.4-macos-aarch64-none/bin/python3.13 cpython-3.13.4+freethreaded-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.12.11-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.11.13-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.10.18-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.9.23-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.9.6-macos-aarch64-none /usr/bin/python3 Export requirements in UV 1 uv export -o requirements.txt Conclusion We have shown how to use uv to start a new project. I also recommend a comprehensive article about uv for people interest in this topic.\n","permalink":"https://nikeasyanzi.github.io/posts/uv/","summary":"\u003cp\u003eIt\u0026rsquo;s been a headache to manage Python packages. But I feel I am saved from that when I meet \u003ca href=\"https://github.com/astral-sh/uv\"\u003eUV\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eThere are two main concerns related to the Python package management problem.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ePython version: Different projects may need different Python interpreters. No one wants to mix them with the system default Python interpreters.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe packages/libraries needed by the project: Intuitively, different projects have different library dependencies. Even if they all rely on a popular library such as OpenSSL, they may depend on different library versions.\u003c/p\u003e","title":"UV: A Python Package Management Tool"},{"content":"I am a software engineer from Taiwan. Mainly focus on Linux, and Self hosting.\n","permalink":"https://nikeasyanzi.github.io/about/","summary":"\u003cp\u003eI am a software engineer from Taiwan. Mainly focus on Linux, and Self hosting.\u003c/p\u003e","title":"About Me"}]