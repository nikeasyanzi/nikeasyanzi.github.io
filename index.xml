<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Craig Yang&#39;s Dev Blog</title>
    <link>https://nikeasyanzi.github.io/</link>
    <description>Recent content on Craig Yang&#39;s Dev Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Jul 2025 16:10:56 +0800</lastBuildDate><atom:link href="https://nikeasyanzi.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Self hosting a local AI in a minute with Ollama and Open WebUI</title>
      <link>https://nikeasyanzi.github.io/posts/self-hosting-chatgpt-in-a-minute/</link>
      <pubDate>Tue, 22 Jul 2025 16:10:56 +0800</pubDate>
      
      <guid>https://nikeasyanzi.github.io/posts/self-hosting-chatgpt-in-a-minute/</guid>
      <description>&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;
&lt;p&gt;With &lt;a href=&#34;https://ollama.com/&#34;&gt;ollama&lt;/a&gt; and &lt;a href=&#34;https://github.com/open-webui/open-webui&#34;&gt;Open WebUI&lt;/a&gt;, self-hosting a chatgpt like service is possible. It&amp;rsquo;s definitely a great news for people or corporations concerning about sharing their data with AI service providers.
In this article, I will show you how to setup a service in local environment.&lt;/p&gt;
&lt;h1 id=&#34;steps&#34;&gt;Steps&lt;/h1&gt;
&lt;p&gt;First of all, there are 2 services we need to setup, and we will host the service on container.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pull &lt;a href=&#34;https://hub.docker.com/r/ollama/ollama&#34;&gt;ollama container image&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-bash=&#34; data-lang=&#34;bash=&#34;&gt;docker pull ollama/ollama:latest
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Before we run the service, we need to download a model from &lt;a href=&#34;https://ollama.com/models&#34;&gt;ollama model&lt;/a&gt;. For experiment, we select llama3.2.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
  &lt;img loading=&#34;lazy&#34; src=&#34;https://i.imgur.com/iwluBge.png&#34; alt=&#34;&#34;  /&gt;&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h1 id="intro">Intro</h1>
<p>With <a href="https://ollama.com/">ollama</a> and <a href="https://github.com/open-webui/open-webui">Open WebUI</a>, self-hosting a chatgpt like service is possible. It&rsquo;s definitely a great news for people or corporations concerning about sharing their data with AI service providers.
In this article, I will show you how to setup a service in local environment.</p>
<h1 id="steps">Steps</h1>
<p>First of all, there are 2 services we need to setup, and we will host the service on container.</p>
<ol>
<li>Pull <a href="https://hub.docker.com/r/ollama/ollama">ollama container image</a></li>
</ol>
<pre tabindex="0"><code class="language-bash=" data-lang="bash=">docker pull ollama/ollama:latest
</code></pre><ol start="2">
<li>Before we run the service, we need to download a model from <a href="https://ollama.com/models">ollama model</a>. For experiment, we select llama3.2.</li>
</ol>
<p>
  <img loading="lazy" src="https://i.imgur.com/iwluBge.png" alt=""  /></p>
<p>
  <img loading="lazy" src="https://i.imgur.com/lnBbjDQ.png" alt=""  /></p>
<pre tabindex="0"><code class="language-bash=" data-lang="bash=">docker exec 5eeaf ollama pull llama3.2
</code></pre><p>Here, I select model llama3.2. It takes a while to download depends on the network and size of selected model.<br>

  <img loading="lazy" src="https://i.imgur.com/DfxrHZv.png" alt=""  /></p>
<ol start="3">
<li>Run ollama service</li>
</ol>
<pre tabindex="0"><code class="language-bash=" data-lang="bash=">docker run -d -v $(PWD):/root/.ollama -p 11434:11434 --name ollama ollama/ollama
</code></pre><ol start="4">
<li>Pull Open Web UI image</li>
</ol>
<pre tabindex="0"><code class="language-bash=" data-lang="bash=">docker pull ghcr.io/open-webui/open-webui:latest
</code></pre><ol start="5">
<li>We create a folder named open-webui. Now, the directory lay out looks like the following.
We see the downloaded llama3.2 model and the new created open-webui folder for Open Web UI data placement..</li>
</ol>
<p>
  <img loading="lazy" src="https://i.imgur.com/OBRCjpR.png" alt=""  /></p>
<ol start="7">
<li>Run Open Web UI image</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">docker run -d -p 3000:8080 --add-host<span class="o">=</span>host.docker.internal:host-gateway -v ./open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</span></span></code></pre></div><p>It would takes a while to get the container ready to work. Once, the status shows healthy, we can try to open http://localhost:3000

  <img loading="lazy" src="https://i.imgur.com/Z1FnT1m.png" alt=""  /></p>
<ol start="8">
<li>For first time login, we will need to register a new account

  <img loading="lazy" src="https://i.imgur.com/iA3YErw.png" alt=""  /></li>
<li>Once we log in with success, we can see the llama3.2 is selected and we can start to play with it.</li>
</ol>
<p>
  <img loading="lazy" src="https://i.imgur.com/WJLODOh.png" alt=""  /></p>
<h1 id="docker-compose-with-service">Docker compose with service</h1>
<p>I also write up a docker compose file, so we can host the file with one click. Check it out.
<a href="https://github.com/nikeasyanzi/my-toolbox/tree/main/ollama_openwebui">https://github.com/nikeasyanzi/my-toolbox/tree/main/ollama_openwebui</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>UV: A Python Package Management Tool</title>
      <link>https://nikeasyanzi.github.io/posts/uv/</link>
      <pubDate>Tue, 01 Jul 2025 22:40:45 +0800</pubDate>
      
      <guid>https://nikeasyanzi.github.io/posts/uv/</guid>
      <description>&lt;p&gt;It&amp;rsquo;s been a headache to manage Python packages. But I feel I am saved from that when I meet &lt;a href=&#34;https://github.com/astral-sh/uv&#34;&gt;UV&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;There are two main concerns related to the Python package management problem.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Python version: Different projects may need different Python interpreters. No one wants to mix them with the system default Python interpreters.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The packages/libraries needed by the project: Intuitively, different projects have different library dependencies. Even if they all rely on a popular library such as OpenSSL, they may depend on different library versions.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>It&rsquo;s been a headache to manage Python packages. But I feel I am saved from that when I meet <a href="https://github.com/astral-sh/uv">UV</a>.</p>
<h2 id="introduction">Introduction</h2>
<p>There are two main concerns related to the Python package management problem.</p>
<ul>
<li>
<p>Python version: Different projects may need different Python interpreters. No one wants to mix them with the system default Python interpreters.</p>
</li>
<li>
<p>The packages/libraries needed by the project: Intuitively, different projects have different library dependencies. Even if they all rely on a popular library such as OpenSSL, they may depend on different library versions.</p>
</li>
</ul>
<p>Some tools are trying to solve the problem.
For example,</p>
<ul>
<li>
<p><a href="https://docs.python.org/3/library/venv.html">venv</a> and <a href="https://github.com/pypa/pip">pip</a> provide package management but are unable to switch between different versions of Python.</p>
</li>
<li>
<p><a href="https://github.com/pyenv/pyenv">Pyenv</a> solves the Python version switching problem but does not support package management.</p>
</li>
</ul>
<p><a href="https://github.com/astral-sh/uv">UV</a> is developed and aimed at solving the aforementioned issues.</p>
<p>Here, I walk through how to use <strong>uv</strong> to manage your project.</p>
<h2 id="walkthrough">Walkthrough</h2>
<h4 id="installation">Installation</h4>
<p>For macOS and Linux. I would use</p>
<pre tabindex="0"><code>curl -LsSf https://astral.sh/uv/install.sh | sh
</code></pre><p>or through <strong>brew</strong> for macOS</p>
<pre tabindex="0"><code>brew install uv
</code></pre><h4 id="important-files">Important files</h4>
<p>The are some key files for UV to manage the project dependency.
In addition, the good news is UV automatically generates and updates these files. Let&rsquo;s take a quick look.</p>
<ul>
<li>
<p>.python-version: contains the Python version used for the project</p>
</li>
<li>
<p>pyproject.toml: serves as the main configuration file for project metadata and dependencies.</p>
</li>
<li>
<p>uv.lock: Lock files for dependency management in UV.</p>
</li>
</ul>
<h4 id="initialization">Initialization</h4>
<pre tabindex="0"><code>$ uv init my-uv
Initialized project `my-uv` at `/Users/craigyang/workplace/my-uv`

$ cd my-uv

$ tree -a -L 1
.
├── .git
├── .gitignore
├── .python-version
├── main.py
├── pyproject.toml
└── README.md

2 directories, 5 files
</code></pre><h4 id="running-python-scripts-with-uv">Running Python scripts with UV</h4>
<p>Let&rsquo;s take a look on the main.py</p>
<pre tabindex="0"><code class="language-python=" data-lang="python=">$ cat main.py
def main():
    print(&#34;Hello from my-uv!&#34;)


if __name__ == &#34;__main__&#34;:
    main()
</code></pre><p>While executing the main.py, a virtual environment is created automatically.</p>
<pre tabindex="0"><code>$ uv run main.py
Using CPython 3.13.4
Creating virtual environment at: .venv
Hello from my-uv!
</code></pre><h4 id="updating-dependencies">Updating dependencies</h4>
<p>Here, we use requests as a new library to be added. We can see the content pyproject.toml is also updated.</p>
<pre tabindex="0"><code>$ uv add requests
Resolved 6 packages in 605ms
Prepared 2 packages in 223ms
Installed 5 packages in 10ms
 + certifi==2025.4.26
 + charset-normalizer==3.4.2
 + idna==3.10
 + requests==2.32.4
 + urllib3==2.4.0
</code></pre><pre tabindex="0"><code>$ cat pyproject.toml
[project]
name = &#34;my-uv&#34;
version = &#34;0.1.0&#34;
description = &#34;Add your description here&#34;
readme = &#34;README.md&#34;
requires-python = &#34;&gt;=3.13&#34;
dependencies = [
    &#34;requests&gt;=2.32.4&#34;,
]
</code></pre><h4 id="managing-python-versions-in-uv">Managing Python Versions in UV</h4>
<p>In the following prompt, we see that for the my-uv project, Python3.13 is the default option, while in the system, it is installed with Python3.9.6</p>
<pre tabindex="0"><code>$ uv python list
cpython-3.14.0b1-macos-aarch64-none                 &lt;download available&gt;
cpython-3.14.0b1+freethreaded-macos-aarch64-none    &lt;download available&gt;
cpython-3.13.4-macos-aarch64-none                   /opt/homebrew/bin/python3.13 -&gt; ../Cellar/python@3.13/3.13.4/bin/python3.13
cpython-3.13.4-macos-aarch64-none                   /opt/homebrew/bin/python3 -&gt; ../Cellar/python@3.13/3.13.4/bin/python3
cpython-3.13.4-macos-aarch64-none                   /Users/craigyang/.local/share/uv/python/cpython-3.13.4-macos-aarch64-none/bin/python3.13
cpython-3.13.4+freethreaded-macos-aarch64-none      &lt;download available&gt;
cpython-3.12.11-macos-aarch64-none                  &lt;download available&gt;
cpython-3.11.13-macos-aarch64-none                  &lt;download available&gt;
cpython-3.10.18-macos-aarch64-none                  &lt;download available&gt;
cpython-3.9.23-macos-aarch64-none                   &lt;download available&gt;
cpython-3.9.6-macos-aarch64-none                    /usr/bin/python3
</code></pre><h4 id="export-requirements-in-uv">Export requirements in UV</h4>
<pre tabindex="0"><code> uv export -o requirements.txt
</code></pre><h2 id="conclusion">Conclusion</h2>
<p>We have shown how to use uv to start a new project.
I also recommend <a href="https://www.datacamp.com/tutorial/python-uv">a comprehensive article about uv</a> for people interest in this topic.</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
